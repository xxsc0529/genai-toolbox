[{"body":"About AlloyDB for PostgreSQL is a fully-managed, PostgreSQL-compatible database for demanding transactional workloads. It provides enterprise-grade performance and availability while maintaining 100% compatibility with open-source PostgreSQL.\nIf you are new to AlloyDB for PostgreSQL, you can create a free trial cluster.\nRequirements IAM Permissions By default, AlloyDB for PostgreSQL source uses the AlloyDB Go Connector to authorize and establish mTLS connections to your AlloyDB instance. The Go connector uses your Application Default Credentials (ADC) to authorize your connection to AlloyDB.\nIn addition to setting the ADC for your server, you need to ensure the IAM identity has been given the following IAM roles (or corresponding permissions):\nroles/alloydb.client roles/serviceusage.serviceUsageConsumer Networking AlloyDB supports connecting over both from external networks via the internet (public IP), and internal networks (private IP). For more information on choosing between the two options, see the AlloyDB page Connection overview.\nYou can configure the ipType parameter in your source configuration to public or private to match your cluster’s configuration. Regardless of which you choose, all connections use IAM-based authorization and are encrypted with mTLS.\nAuthentication This source supports both password-based authentication and IAM authentication (using your Application Default Credentials).\nStandard Authentication To connect using user/password, create a PostgreSQL user and input your credentials in the user and password fields.\nuser: ${USER_NAME} password: ${PASSWORD} IAM Authentication To connect using IAM authentication:\nPrepare your database instance and user following this guide. You could choose one of the two ways to log in: Specify your IAM email as the user. Leave your user field blank. Toolbox will fetch the ADC automatically and log in using the email associated with it. Leave the password field blank. Example sources: my-alloydb-pg-source: kind: alloydb-postgres project: my-project-id region: us-central1 cluster: my-cluster instance: my-instance database: my_db user: ${USER_NAME} password: ${PASSWORD} # ipType: \"public\" Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nReference field type required description kind string true Must be “alloydb-postgres”. project string true Id of the GCP project that the cluster was created in (e.g. “my-project-id”). region string true Name of the GCP region that the cluster was created in (e.g. “us-central1”). cluster string true Name of the AlloyDB cluster (e.g. “my-cluster”). instance string true Name of the AlloyDB instance within the cluster (e.g. “my-instance”). database string true Name of the Postgres database to connect to (e.g. “my_db”). user string false Name of the Postgres user to connect as (e.g. “my-pg-user”). Defaults to IAM auth using ADC email if unspecified. password string false Password of the Postgres user (e.g. “my-password”). Defaults to attempting IAM authentication if unspecified. ipType string false IP Type of the AlloyDB instance; must be one of public or private. Default: public. ","categories":"","description":"AlloyDB for PostgreSQL is a fully-managed, PostgreSQL-compatible database for  demanding transactional workloads.\n","excerpt":"AlloyDB for PostgreSQL is a fully-managed, PostgreSQL-compatible …","ref":"/genai-toolbox/resources/sources/alloydb-pg/","tags":"","title":"AlloyDB for PostgreSQL"},{"body":"","categories":"","description":"AlloyDB AI NL Tool.\n","excerpt":"AlloyDB AI NL Tool.\n","ref":"/genai-toolbox/resources/tools/alloydbainl/","tags":"","title":"AlloyDB AI NL"},{"body":"About The alloydb-ai-nl tool leverages AlloyDB AI next-generation natural Language support to allow an Agent the ability to query the database directly using natural language. Natural language streamlines the development of generative AI applications by transferring the complexity of converting natural language to SQL from the application layer to the database layer.\nThis tool is compatible with the following sources:\nalloydb-postgres AlloyDB AI Natural Language delivers secure and accurate responses for application end user natural language questions. Natural language streamlines the development of generative AI applications by transferring the complexity of converting natural language to SQL from the application layer to the database layer.\nRequirements Tip\nAlloyDB AI natural language is currently in gated public preview. For more information on availability and limitations, please see AlloyDB AI natural language overview\nTo enable AlloyDB AI natural language for your AlloyDB cluster, please follow the steps listed in the Generate SQL queries that answer natural language questions, including enabling the extension and configuring context for your application.\nConfiguration Specifying an nl_config A nl_config is a configuration that associates an application to schema objects, examples and other contexts that can be used. A large application can also use different configurations for different parts of the app, as long as the correct configuration can be specified when a question is sent from that part of the application.\nOnce you’ve followed the steps for configuring context, you can use the context field when configuring a alloydb-ai-nl tool. When this tool is invoked, the SQL will be generated and executed using this context.\nSpecifying Parameters to PSV’s Parameterized Secure Views (PSVs) are a feature unique to AlloyDB that allows you to require one or more named parameter values passed to the view when querying it, somewhat like bind variables with ordinary database queries.\nYou can use the nlConfigParameters to list the parameters required for your nl_config. You must supply all parameters required for all PSVs in the context. It’s strongly recommended to use features like Authenticated Parameters or Bound Parameters to provide secure access to queries generated using natural language, as these parameters are not visible to the LLM.\nExample tools: ask_questions: kind: alloydb-ai-nl source: my-alloydb-source description: \"Ask questions to check information about flights\" nlConfig: \"cymbal_air_nl_config\" nlConfigParameters: - name: user_email type: string description: User ID of the logged in user. # note: we strongly recommend using features like Authenticated or # Bound parameters to prevent the LLM from seeing these params and # specifying values it shouldn't in the tool input authServices: - name: my_google_service field: email Reference field type required description kind string true Must be “alloydb-ai-nl”. source string true Name of the AlloyDB source the natural language query should execute on. description string true Description of the tool that is passed to the LLM. nlConfig string true The name of the nl_config in AlloyDB nlConfigParameters parameters true List of PSV parameters defined in the nl_config ","categories":"","description":"The \"alloydb-ai-nl\" tool leverages  [AlloyDB AI](https://cloud.google.com/alloydb/ai) next-generation Natural  Language support to provide the ability to query the database directly using natural language.\n","excerpt":"The \"alloydb-ai-nl\" tool leverages  [AlloyDB …","ref":"/genai-toolbox/resources/tools/alloydbainl/alloydb-ai-nl/","tags":"","title":"alloydb-ai-nl"},{"body":"AuthServices represent services that handle authentication and authorization. It can primarily be used by Tools in two different ways:\nAuthorized Invocation is when a tool is validated by the auth service before the call can be invoked. Toolbox will reject any calls that fail to validate or have an invalid token. Authenticated Parameters replace the value of a parameter with a field from an OIDC claim. Toolbox will automatically resolve the ID token provided by the client and replace the parameter in the tool call. Example The following configurations are placed at the top level of a tools.yaml file.\nTip\nIf you are accessing Toolbox with multiple applications, each application should register their own Client ID even if they use the same “kind” of auth provider.\nauthServices: my_auth_app_1: kind: google clientId: ${YOUR_CLIENT_ID_1} my_auth_app_2: kind: google clientId: ${YOUR_CLIENT_ID_2} Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nAfter you’ve configured an authService you’ll, need to reference it in the configuration for each tool that should use it:\nAuthorized Invocations for authorizing a tool call, use the authRequired field in a tool config Authenticated Parameters for using the value from a OIDC claim, use the authServices field in a parameter config Specifying ID Tokens from Clients After configuring your authServices section, use a Toolbox SDK to add your ID tokens to the header of a Tool invocation request. When specifying a token you will provide a function (that returns an id). This function is called when the tool is invoked. This allows you to cache and refresh the ID token as needed.\nThe primary method for providing these getters is via the auth_token_getters parameter when loading tools, or the add_auth_token_getter() / add_auth_token_getters() methods on a loaded tool object.\nSpecifying tokens during load Core LangChain Llamaindex import asyncio from toolbox_core import ToolboxClient async def get_auth_token(): # ... Logic to retrieve ID token (e.g., from local storage, OAuth flow) # This example just returns a placeholder. Replace with your actual token retrieval. return \"YOUR_ID_TOKEN\" # Placeholder async def main(): async with ToolboxClient(\"\u003chttp://127.0.0.1:5000\u003e\") as toolbox: auth_tool = await toolbox.load_tool( \"get_sensitive_data\", auth_token_getters={\"my_auth_app_1\": get_auth_token} ) result = await auth_tool(param=\"value\") print(result) if **name** == \"**main**\": asyncio.run(main()) import asyncio from toolbox_langchain import ToolboxClient async def get_auth_token(): # ... Logic to retrieve ID token (e.g., from local storage, OAuth flow) # This example just returns a placeholder. Replace with your actual token retrieval. return \"YOUR_ID_TOKEN\" # Placeholder async def main(): toolbox = ToolboxClient(\"\u003chttp://127.0.0.1:5000\u003e\") auth_tool = await toolbox.aload_tool( \"get_sensitive_data\", auth_token_getters={\"my_auth_app_1\": get_auth_token} ) result = await auth_tool.ainvoke({\"param\": \"value\"}) print(result) if **name** == \"**main**\": asyncio.run(main()) import asyncio from toolbox_llamaindex import ToolboxClient async def get_auth_token(): # ... Logic to retrieve ID token (e.g., from local storage, OAuth flow) # This example just returns a placeholder. Replace with your actual token retrieval. return \"YOUR_ID_TOKEN\" # Placeholder async def main(): toolbox = ToolboxClient(\"\u003chttp://127.0.0.1:5000\u003e\") auth_tool = await toolbox.aload_tool( \"get_sensitive_data\", auth_token_getters={\"my_auth_app_1\": get_auth_token} ) # result = await auth_tool.acall(param=\"value\") # print(result.content) if **name** == \"**main**\": asyncio.run(main()) Specifying tokens for existing tools Core LangChain Llamaindex tools = await toolbox.load_toolset() # for a single token authorized_tool = tools[0].add_auth_token_getter(\"my_auth\", get_auth_token) # OR, if multiple tokens are needed authorized_tool = tools[0].add_auth_token_getters({ \"my_auth1\": get_auth1_token, \"my_auth2\": get_auth2_token, }) tools = toolbox.load_toolset() # for a single token authorized_tool = tools[0].add_auth_token_getter(\"my_auth\", get_auth_token) # OR, if multiple tokens are needed authorized_tool = tools[0].add_auth_token_getters({ \"my_auth1\": get_auth1_token, \"my_auth2\": get_auth2_token, }) tools = toolbox.load_toolset() # for a single token authorized_tool = tools[0].add_auth_token_getter(\"my_auth\", get_auth_token) # OR, if multiple tokens are needed authorized_tool = tools[0].add_auth_token_getters({ \"my_auth1\": get_auth1_token, \"my_auth2\": get_auth2_token, }) Kinds of Auth Services ","categories":"","description":"AuthServices represent services that handle authentication and authorization. \n","excerpt":"AuthServices represent services that handle authentication and …","ref":"/genai-toolbox/resources/authservices/","tags":"","title":"AuthServices"},{"body":"BigQuery Source BigQuery is Google Cloud’s fully managed, petabyte-scale, and cost-effective analytics data warehouse that lets you run analytics over vast amounts of data in near real time. With BigQuery, there’s no infrastructure to set up or manage, letting you focus on finding meaningful insights using GoogleSQL and taking advantage of flexible pricing models across on-demand and flat-rate options.\nIf you are new to BigQuery, you can try to load and query data with the bq tool.\nBigQuery uses GoogleSQL for querying data. GoogleSQL is an ANSI-compliant structured query language (SQL) that is also implemented for other Google Cloud services. SQL queries are handled by cluster nodes in the same way as NoSQL data requests. Therefore, the same best practices apply when creating SQL queries to run against your BigQuery data, such as avoiding full table scans or complex filters.\nRequirements IAM Permissions BigQuery uses Identity and Access Management (IAM) to control user and group access to BigQuery resources like projects, datasets, and tables. Toolbox will use your Application Default Credentials (ADC) to authorize and authenticate when interacting with BigQuery.\nIn addition to setting the ADC for your server, you need to ensure the IAM identity has been given the correct IAM permissions for the queries you intend to run. Common roles include roles/bigquery.user (which includes permissions to run jobs and read data) or roles/bigquery.dataViewer. See Introduction to BigQuery IAM for more information on applying IAM permissions and roles to an identity.\nExample sources: my-bigquery-source: kind: \"bigquery\" project: \"my-project-id\" Reference field type required description kind string true Must be “bigquery”. project string true Id of the GCP project that the cluster was created in (e.g. “my-project-id”). location string false Specifies the location (e.g., ‘us’, ‘asia-northeast1’) in which to run the query job. This location must match the location of any tables referenced in the query. The default behavior is for it to be executed in the US multi-region ","categories":"","description":"BigQuery is Google Cloud's fully managed, petabyte-scale, and cost-effective analytics data warehouse that lets you run analytics over vast amounts of  data in near real time. With BigQuery, there's no infrastructure to set  up or manage, letting you focus on finding meaningful insights using  GoogleSQL and taking advantage of flexible pricing models across on-demand  and flat-rate options.\n","excerpt":"BigQuery is Google Cloud's fully managed, petabyte-scale, and …","ref":"/genai-toolbox/resources/sources/bigquery/","tags":"","title":"BigQuery"},{"body":"","categories":"","description":"Tools that work with BigQuery Sources.\n","excerpt":"Tools that work with BigQuery Sources.\n","ref":"/genai-toolbox/resources/tools/bigquery/","tags":"","title":"BigQuery"},{"body":"","categories":"","description":"How to get started with Toolbox using BigQuery.\n","excerpt":"How to get started with Toolbox using BigQuery.\n","ref":"/genai-toolbox/samples/bigquery/","tags":"","title":"BigQuery"},{"body":"About A bigquery-execute-sql tool executes a SQL statement against BigQuery. It’s compatible with the following sources:\nbigquery bigquery-execute-sql takes one input parameter sql and runs the sql statement against the source.\nExample tools: execute_sql_tool: kind: bigquery-execute-sql source: my-bigquery-source description: Use this tool to execute sql statement. Reference field type required description kind string true Must be “bigquery-execute-sql”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. ","categories":"","description":"A \"bigquery-execute-sql\" tool executes a SQL statement against BigQuery.\n","excerpt":"A \"bigquery-execute-sql\" tool executes a SQL statement against …","ref":"/genai-toolbox/resources/tools/bigquery/bigquery-execute-sql/","tags":"","title":"bigquery-execute-sql"},{"body":"About A bigquery-get-dataset-info tool retrieves metadata for a BigQuery dataset. It’s compatible with the following sources:\nbigquery bigquery-get-dataset-info takes a dataset parameter to specify the dataset on the given source. It also optionally accepts a project parameter to define the Google Cloud project ID. If the project parameter is not provided, the tool defaults to using the project defined in the source configuration.\nExample tools: bigquery_get_dataset_info: kind: bigquery-get-dataset-info source: my-bigquery-source description: Use this tool to get dataset metadata. Reference field type required description kind string true Must be “bigquery-get-dataset-info”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. ","categories":"","description":"A \"bigquery-get-dataset-info\" tool retrieves metadata for a BigQuery dataset.\n","excerpt":"A \"bigquery-get-dataset-info\" tool retrieves metadata for a BigQuery …","ref":"/genai-toolbox/resources/tools/bigquery/bigquery-get-dataset-info/","tags":"","title":"bigquery-get-dataset-info"},{"body":"About A bigquery-get-table-info tool retrieves metadata for a BigQuery table. It’s compatible with the following sources:\nbigquery bigquery-get-table-info takes dataset and table parameters to specify the target table. It also optionally accepts a project parameter to define the Google Cloud project ID. If the project parameter is not provided, the tool defaults to using the project defined in the source configuration.\nExample tools: bigquery_get_table_info: kind: bigquery-get-table-info source: my-bigquery-source description: Use this tool to get table metadata. Reference field type required description kind string true Must be “bigquery-get-table-info”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. ","categories":"","description":"A \"bigquery-get-table-info\" tool retrieves metadata for a BigQuery table.\n","excerpt":"A \"bigquery-get-table-info\" tool retrieves metadata for a BigQuery …","ref":"/genai-toolbox/resources/tools/bigquery/bigquery-get-table-info/","tags":"","title":"bigquery-get-table-info"},{"body":"About A bigquery-list-dataset-ids tool returns all dataset IDs from the source. It’s compatible with the following sources:\nbigquery bigquery-list-dataset-ids optionally accepts a project parameter to define the Google Cloud project ID. If the project parameter is not provided, the tool defaults to using the project defined in the source configuration.\nExample tools: bigquery_list_dataset_ids: kind: bigquery-list-dataset-ids source: my-bigquery-source description: Use this tool to get dataset metadata. Reference field type required description kind string true Must be “bigquery-list-dataset-ids”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. ","categories":"","description":"A \"bigquery-list-dataset-ids\" tool returns all dataset IDs from the source.\n","excerpt":"A \"bigquery-list-dataset-ids\" tool returns all dataset IDs from the …","ref":"/genai-toolbox/resources/tools/bigquery/bigquery-list-dataset-ids/","tags":"","title":"bigquery-list-dataset-ids"},{"body":"About A bigquery-list-table-ids tool returns table IDs in a given BigQuery dataset. It’s compatible with the following sources:\nbigquery bigquery-get-dataset-info takes a required dataset parameter to specify the dataset from which to list table IDs. It also optionally accepts a project parameter to define the Google Cloud project ID. If the project parameter is not provided, the tool defaults to using the project defined in the source configuration.\nExample tools: bigquery_list_table_ids: kind: bigquery-list-table-ids source: my-bigquery-source description: Use this tool to get table metadata. Reference field type required description kind string true Must be “bigquery-list-table-ids”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. ","categories":"","description":"A \"bigquery-list-table-ids\" tool returns table IDs in a given BigQuery dataset.\n","excerpt":"A \"bigquery-list-table-ids\" tool returns table IDs in a given BigQuery …","ref":"/genai-toolbox/resources/tools/bigquery/bigquery-list-table-ids/","tags":"","title":"bigquery-list-table-ids"},{"body":"About A bigquery-sql tool executes a pre-defined SQL statement. It’s compatible with the following sources:\nbigquery GoogleSQL BigQuery uses GoogleSQL for querying data. The integration with Toolbox supports this dialect. The specified SQL statement is executed, and parameters can be inserted into the query. BigQuery supports both named parameters (e.g., @name) and positional parameters (?), but they cannot be mixed in the same query.\nExample Note: This tool uses parameterized queries to prevent SQL injections. Query parameters can be used as substitutes for arbitrary expressions. Parameters cannot be used as substitutes for identifiers, column names, table names, or other parts of the query.\ntools: # Example: Querying a user table in BigQuery search_users_bq: kind: bigquery-sql source: my-bigquery-source statement: | SELECT id, name, email FROM `my-project.my-dataset.users` WHERE id = @id OR email = @email; description: | Use this tool to get information for a specific user. Takes an id number or a name and returns info on the user. Example: {{ \"id\": 123, \"name\": \"Alice\", }} parameters: - name: id type: integer description: User ID - name: email type: string description: Email address of the user Example with Template Parameters Note: This tool allows direct modifications to the SQL statement, including identifiers, column names, and table names. This makes it more vulnerable to SQL injections. Using basic parameters only (see above) is recommended for performance and safety reasons. For more details, please check templateParameters.\ntools: list_table: kind: bigquery-sql source: my-bigquery-source statement: | SELECT * FROM {{.tableName}}; description: | Use this tool to list all information from a specific table. Example: {{ \"tableName\": \"flights\", }} templateParameters: - name: tableName type: string description: Table to select from Reference field type required description kind string true Must be “bigquery-sql”. source string true Name of the source the GoogleSQL should execute on. description string true Description of the tool that is passed to the LLM. statement string true The GoogleSQL statement to execute. parameters parameters false List of parameters that will be inserted into the SQL statement. templateParameters templateParameters false List of templateParameters that will be inserted into the SQL statement before executing prepared statement. ","categories":"","description":"A \"bigquery-sql\" tool executes a pre-defined SQL statement.\n","excerpt":"A \"bigquery-sql\" tool executes a pre-defined SQL statement.\n","ref":"/genai-toolbox/resources/tools/bigquery/bigquery-sql/","tags":"","title":"bigquery-sql"},{"body":"Bigtable Source Bigtable is a low-latency NoSQL database service for machine learning, operational analytics, and user-facing operations. It’s a wide-column, key-value store that can scale to billions of rows and thousands of columns. With Bigtable, you can replicate your data to regions across the world for high availability and data resiliency.\nIf you are new to Bigtable, you can try to create an instance and write data with the cbt CLI.\nYou can use GoogleSQL statements to query your Bigtable data. GoogleSQL is an ANSI-compliant structured query language (SQL) that is also implemented for other Google Cloud services. SQL queries are handled by cluster nodes in the same way as NoSQL data requests. Therefore, the same best practices apply when creating SQL queries to run against your Bigtable data, such as avoiding full table scans or complex filters.\nRequirements IAM Permissions Bigtable uses Identity and Access Management (IAM) to control user and group access to Bigtable resources at the project, instance, table, and backup level. Toolbox will use your Application Default Credentials (ADC) to authorize and authenticate when interacting with Bigtable.\nIn addition to setting the ADC for your server, you need to ensure the IAM identity has been given the correct IAM permissions for the query provided. See Apply IAM roles for more information on applying IAM permissions and roles to an identity.\nExample sources: my-bigtable-source: kind: \"bigtable\" project: \"my-project-id\" instance: \"test-instance\" Reference field type required description kind string true Must be “bigtable”. project string true Id of the GCP project that the cluster was created in (e.g. “my-project-id”). instance string true Name of the Bigtable instance. ","categories":"","description":"Bigtable is a low-latency NoSQL database service for machine learning, operational analytics, and user-facing operations. It's a wide-column, key-value store that can scale to billions of rows and thousands of columns. With Bigtable, you can replicate your data to regions across the world for high availability and data resiliency.\n","excerpt":"Bigtable is a low-latency NoSQL database service for machine learning, …","ref":"/genai-toolbox/resources/sources/bigtable/","tags":"","title":"Bigtable"},{"body":"","categories":"","description":"Tools that work with Bigtable Sources.\n","excerpt":"Tools that work with Bigtable Sources.\n","ref":"/genai-toolbox/resources/tools/bigtable/","tags":"","title":"Bigtable"},{"body":"About A bigtable-sql tool executes a pre-defined SQL statement against a Bigtable instance. It’s compatible with any of the following sources:\nbigtable GoogleSQL Bigtable supports SQL queries. The integration with Toolbox supports googlesql dialect, the specified SQL statement is executed as a data manipulation language (DML) statements, and specified parameters will inserted according to their name: e.g. @name.\nExample Note: This tool uses parameterized queries to prevent SQL injections. Query parameters can be used as substitutes for arbitrary expressions. Parameters cannot be used as substitutes for identifiers, column names, table names, or other parts of the query.\ntools: search_user_by_id_or_name: kind: bigtable-sql source: my-bigtable-instance statement: | SELECT TO_INT64(cf[ 'id' ]) as id, CAST(cf[ 'name' ] AS string) as name, FROM mytable WHERE TO_INT64(cf[ 'id' ]) = @id OR CAST(cf[ 'name' ] AS string) = @name; description: | Use this tool to get information for a specific user. Takes an id number or a name and returns info on the user. Example: {{ \"id\": 123, \"name\": \"Alice\", }} parameters: - name: id type: integer description: User ID - name: name type: string description: Name of the user Example with Template Parameters Note: This tool allows direct modifications to the SQL statement, including identifiers, column names, and table names. This makes it more vulnerable to SQL injections. Using basic parameters only (see above) is recommended for performance and safety reasons. For more details, please check templateParameters.\ntools: list_table: kind: bigtable-sql source: my-bigtable-instance statement: | SELECT * FROM {{.tableName}}; description: | Use this tool to list all information from a specific table. Example: {{ \"tableName\": \"flights\", }} templateParameters: - name: tableName type: string description: Table to select from Reference field type required description kind string true Must be “bigtable-sql”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. statement string true SQL statement to execute on. parameters parameters false List of parameters that will be inserted into the SQL statement. templateParameters templateParameters false List of templateParameters that will be inserted into the SQL statement before executing prepared statement. Tips Bigtable Studio is a useful to explore and manage your Bigtable data. If you’re unfamiliar with the query syntax, Query Builder lets you build a query, run it against a table, and then view the results in the console. Some Python libraries limit the use of underscore columns such as _key. A workaround would be to leverage Bigtable Logical Views to rename the columns. ","categories":"","description":"A \"bigtable-sql\" tool executes a pre-defined SQL statement against a Google  Cloud Bigtable instance.\n","excerpt":"A \"bigtable-sql\" tool executes a pre-defined SQL statement against a …","ref":"/genai-toolbox/resources/tools/bigtable/bigtable-sql/","tags":"","title":"bigtable-sql"},{"body":"About Cloud SQL for MySQL is a fully-managed database service that helps you set up, maintain, manage, and administer your MySQL relational databases on Google Cloud Platform.\nIf you are new to Cloud SQL for MySQL, you can try creating and connecting to a database by following these instructions.\nRequirements IAM Permissions By default, this source uses the Cloud SQL Go Connector to authorize and establish mTLS connections to your Cloud SQL instance. The Go connector uses your Application Default Credentials (ADC) to authorize your connection to Cloud SQL.\nIn addition to setting the ADC for your server, you need to ensure the IAM identity has been given the following IAM roles (or corresponding permissions):\nroles/cloudsql.client Tip\nIf you are connecting from Compute Engine, make sure your VM also has the proper scope to connect using the Cloud SQL Admin API.\nNetworking Cloud SQL supports connecting over both from external networks via the internet (public IP), and internal networks (private IP). For more information on choosing between the two options, see the Cloud SQL page Connection overview.\nYou can configure the ipType parameter in your source configuration to public or private to match your cluster’s configuration. Regardless of which you choose, all connections use IAM-based authorization and are encrypted with mTLS.\nDatabase User Currently, this source only uses standard authentication. You will need to create a MySQL user to login to the database with.\nExample sources: my-cloud-sql-mysql-source: kind: cloud-sql-mysql project: my-project-id region: us-central1 instance: my-instance database: my_db user: ${USER_NAME} password: ${PASSWORD} # ipType: \"private\" Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nReference field type required description kind string true Must be “cloud-sql-mysql”. project string true Id of the GCP project that the cluster was created in (e.g. “my-project-id”). region string true Name of the GCP region that the cluster was created in (e.g. “us-central1”). instance string true Name of the Cloud SQL instance within the cluster (e.g. “my-instance”). database string true Name of the MySQL database to connect to (e.g. “my_db”). user string true Name of the MySQL user to connect as (e.g. “my-pg-user”). password string true Password of the MySQL user (e.g. “my-password”). ipType string false IP Type of the Cloud SQL instance; must be one of public or private. Default: public. ","categories":"","description":"Cloud SQL for MySQL is a fully-managed database service for MySQL.\n","excerpt":"Cloud SQL for MySQL is a fully-managed database service for MySQL.\n","ref":"/genai-toolbox/resources/sources/cloud-sql-mysql/","tags":"","title":"Cloud SQL for MySQL"},{"body":"About Cloud SQL for PostgreSQL is a fully-managed database service that helps you set up, maintain, manage, and administer your PostgreSQL relational databases on Google Cloud Platform.\nIf you are new to Cloud SQL for PostgreSQL, you can try creating and connecting to a database by following these instructions.\nRequirements IAM Permissions By default, this source uses the Cloud SQL Go Connector to authorize and establish mTLS connections to your Cloud SQL instance. The Go connector uses your Application Default Credentials (ADC) to authorize your connection to Cloud SQL.\nIn addition to setting the ADC for your server, you need to ensure the IAM identity has been given the following IAM roles (or corresponding permissions):\nroles/cloudsql.client Tip\nIf you are connecting from Compute Engine, make sure your VM also has the proper scope to connect using the Cloud SQL Admin API.\nNetworking Cloud SQL supports connecting over both from external networks via the internet (public IP), and internal networks (private IP). For more information on choosing between the two options, see the Cloud SQL page Connection overview.\nYou can configure the ipType parameter in your source configuration to public or private to match your cluster’s configuration. Regardless of which you choose, all connections use IAM-based authorization and are encrypted with mTLS.\nAuthentication This source supports both password-based authentication and IAM authentication (using your Application Default Credentials).\nStandard Authentication To connect using user/password, create a PostgreSQL user and input your credentials in the user and password fields.\nuser: ${USER_NAME} password: ${PASSWORD} IAM Authentication To connect using IAM authentication:\nPrepare your database instance and user following this guide.\nYou could choose one of the two ways to log in:\nSpecify your IAM email as the user. Leave your user field blank. Toolbox will fetch the ADC automatically and log in using the email associated with it. Leave the password field blank.\nExample sources: my-cloud-sql-pg-source: kind: cloud-sql-postgres project: my-project-id region: us-central1 instance: my-instance database: my_db user: ${USER_NAME} password: ${PASSWORD} # ipType: \"private\" Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nReference field type required description kind string true Must be “cloud-sql-postgres”. project string true Id of the GCP project that the cluster was created in (e.g. “my-project-id”). region string true Name of the GCP region that the cluster was created in (e.g. “us-central1”). instance string true Name of the Cloud SQL instance within the cluster (e.g. “my-instance”). database string true Name of the Postgres database to connect to (e.g. “my_db”). user string false Name of the Postgres user to connect as (e.g. “my-pg-user”). Defaults to IAM auth using ADC email if unspecified. password string false Password of the Postgres user (e.g. “my-password”). Defaults to attempting IAM authentication if unspecified. ipType string false IP Type of the Cloud SQL instance; must be one of public or private. Default: public. ","categories":"","description":"Cloud SQL for PostgreSQL is a fully-managed database service for Postgres.\n","excerpt":"Cloud SQL for PostgreSQL is a fully-managed database service for …","ref":"/genai-toolbox/resources/sources/cloud-sql-pg/","tags":"","title":"Cloud SQL for PostgreSQL"},{"body":"About Cloud SQL for SQL Server is a managed database service that helps you set up, maintain, manage, and administer your SQL Server databases on Google Cloud.\nIf you are new to Cloud SQL for SQL Server, you can try creating and connecting to a database by following these instructions.\nRequirements IAM Permissions By default, this source uses the Cloud SQL Go Connector to authorize and establish mTLS connections to your Cloud SQL instance. The Go connector uses your Application Default Credentials (ADC) to authorize your connection to Cloud SQL.\nIn addition to setting the ADC for your server, you need to ensure the IAM identity has been given the following IAM roles (or corresponding permissions):\nroles/cloudsql.client Tip\nIf you are connecting from Compute Engine, make sure your VM also has the proper scope to connect using the Cloud SQL Admin API.\nNetworking Cloud SQL supports connecting over both from external networks via the internet (public IP), and internal networks (private IP). For more information on choosing between the two options, see the Cloud SQL page Connection overview.\nYou can configure the ipType parameter in your source configuration to public or private to match your cluster’s configuration. Regardless of which you choose, all connections use IAM-based authorization and are encrypted with mTLS.\nDatabase User Currently, this source only uses standard authentication. You will need to create a SQL Server user to login to the database with.\nExample sources: my-cloud-sql-mssql-instance: kind: cloud-sql-mssql project: my-project region: my-region instance: my-instance database: my_db ipAddress: localhost user: ${USER_NAME} password: ${PASSWORD} # ipType: private Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nReference field type required description kind string true Must be “cloud-sql-mssql”. project string true Id of the GCP project that the cluster was created in (e.g. “my-project-id”). region string true Name of the GCP region that the cluster was created in (e.g. “us-central1”). instance string true Name of the Cloud SQL instance within the cluster (e.g. “my-instance”). database string true Name of the Cloud SQL database to connect to (e.g. “my_db”). ipAddress string true IP address of the Cloud SQL instance to connect to. user string true Name of the SQL Server user to connect as (e.g. “my-pg-user”). password string true Password of the SQL Server user (e.g. “my-password”). ipType string false IP Type of the Cloud SQL instance, must be either public or private. Default: public. ","categories":"","description":"Cloud SQL for SQL Server is a fully-managed database service for SQL Server.\n","excerpt":"Cloud SQL for SQL Server is a fully-managed database service for SQL …","ref":"/genai-toolbox/resources/sources/cloud-sql-mssql/","tags":"","title":"Cloud SQL for SQL Server"},{"body":"","categories":"","description":"List of guides detailing how to connect your AI tools (IDEs) to Toolbox using MCP.\n","excerpt":"List of guides detailing how to connect your AI tools (IDEs) to …","ref":"/genai-toolbox/how-to/connect-ide/","tags":"","title":"Connect from your IDE"},{"body":"Toolbox SDKs vs Model Context Protocol (MCP) Toolbox now supports connections via both the native Toolbox SDKs and via Model Context Protocol (MCP). However, Toolbox has several features which are not supported in the MCP specification (such as Authenticated Parameters and Authorized invocation).\nWe recommend using the native SDKs over MCP clients to leverage these features. The native SDKs can be combined with MCP clients in many cases.\nProtocol Versions Toolbox currently supports the following versions of MCP specification:\n2024-11-05 Features Not Supported by MCP Toolbox has several features that are not yet supported in the MCP specification:\nAuthZ/AuthN: There are no auth implementation in the 2024-11-05 specification. This includes: Authenticated Parameters Authorized Invocations Notifications: Currently, editing Toolbox Tools requires a server restart. Clients should reload tools on disconnect to get the latest version. Connecting to Toolbox with an MCP client Before you begin Note\nMCP is only compatible with Toolbox version 0.3.0 and above.\nInstall Toolbox version 0.3.0+.\nMake sure you’ve set up and initialized your database.\nSet up your tools.yaml file.\nConnecting via Standard Input/Output (stdio) Toolbox supports the stdio transport protocol. Users that wish to use stdio will have to include the --stdio flag when running Toolbox.\n./toolbox --stdio When running with stdio, Toolbox will listen via stdio instead of acting as a remote HTTP server. Logs will be set to the warn level by default. debug and info logs are not supported with stdio.\nNote\nToolbox enables dynamic reloading by default. To disable, use the --disable-reload flag.\nConnecting via HTTP Toolbox supports the HTTP transport protocol with and without SSE.\nHTTP with SSE HTTP POST Add the following configuration to your MCP client configuration:\n{ \"mcpServers\": { \"toolbox\": { \"type\": \"sse\", \"url\": \"http://127.0.0.1:5000/mcp/sse\", } } } If you would like to connect to a specific toolset, replace url with \"http://127.0.0.1:5000/mcp/{toolset_name}/sse\".\nConnect to Toolbox HTTP POST via http://127.0.0.1:5000/mcp.\nIf you would like to connect to a specific toolset, connect via http://127.0.0.1:5000/mcp/{toolset_name}.\nUsing the MCP Inspector with Toolbox Use MCP Inspector for testing and debugging Toolbox server.\nSTDIO HTTP with SSE Run Inspector with Toolbox as a subprocess:\nnpx @modelcontextprotocol/inspector ./toolbox --stdio For Transport Type dropdown menu, select STDIO.\nIn Command, make sure that it is set to :./toolbox (or the correct path to where the Toolbox binary is installed).\nIn Arguments, make sure that it’s filled with --stdio.\nClick the Connect button. It might take awhile to spin up Toolbox. Voila! You should be able to inspect your toolbox tools!\nRun Toolbox.\nIn a separate terminal, run Inspector directly through npx:\nnpx @modelcontextprotocol/inspector For Transport Type dropdown menu, select SSE.\nFor URL, type in http://127.0.0.1:5000/mcp/sse to use all tool or http//127.0.0.1:5000/mcp/{toolset_name}/sse to use a specific toolset.\nClick the Connect button. Voila! You should be able to inspect your toolbox tools!\nTested Clients Client SSE Works MCP Config Docs Claude Desktop ✅ https://modelcontextprotocol.io/quickstart/user#1-download-claude-for-desktop MCP Inspector ✅ https://github.com/modelcontextprotocol/inspector Cursor ✅ https://docs.cursor.com/context/model-context-protocol Windsurf ✅ https://docs.windsurf.com/windsurf/mcp VS Code (Insiders) ✅ https://code.visualstudio.com/docs/copilot/chat/mcp-servers ","categories":"","description":"How to connect to Toolbox from a MCP Client.\n","excerpt":"How to connect to Toolbox from a MCP Client.\n","ref":"/genai-toolbox/how-to/connect_via_mcp/","tags":"","title":"Connect via MCP Client"},{"body":"About A couchbase source establishes a connection to a Couchbase database cluster, allowing tools to execute SQL queries against it.\nExample sources: my-couchbase-instance: kind: couchbase connectionString: couchbase://localhost:8091 bucket: travel-sample scope: inventory username: Administrator password: password Reference field type required description kind string true Must be “couchbase”. connectionString string true Connection string for the Couchbase cluster. bucket string true Name of the bucket to connect to. scope string true Name of the scope within the bucket. username string false Username for authentication. password string false Password for authentication. clientCert string false Path to client certificate file for TLS authentication. clientCertPassword string false Password for the client certificate. clientKey string false Path to client key file for TLS authentication. clientKeyPassword string false Password for the client key. caCert string false Path to CA certificate file. noSslVerify boolean false If true, skip server certificate verification. Warning: This option should only be used in development or testing environments. Disabling SSL verification poses significant security risks in production as it makes your connection vulnerable to man-in-the-middle attacks. profile string false Name of the connection profile to apply. queryScanConsistency integer false Query scan consistency. Controls the consistency guarantee for index scanning. Values: 1 for “not_bounded” (fastest option, but results may not include the most recent operations), 2 for “request_plus” (highest consistency level, includes all operations up until the query started, but incurs a performance penalty). If not specified, defaults to the Couchbase Go SDK default. ","categories":"","description":"A \"couchbase\" source connects to a Couchbase database.\n","excerpt":"A \"couchbase\" source connects to a Couchbase database.\n","ref":"/genai-toolbox/resources/sources/couchbase/","tags":"","title":"couchbase"},{"body":"","categories":"","description":"Tools that work with Couchbase Sources.\n","excerpt":"Tools that work with Couchbase Sources.\n","ref":"/genai-toolbox/resources/tools/couchbase/","tags":"","title":"Couchbase"},{"body":"About A couchbase-sql tool executes a pre-defined SQL statement against a Couchbase database. It’s compatible with any of the following sources:\ncouchbase The specified SQL statement is executed as a parameterized statement, and specified parameters will be used according to their name: e.g. $id.\nExample Note: This tool uses parameterized queries to prevent SQL injections. Query parameters can be used as substitutes for arbitrary expressions. Parameters cannot be used as substitutes for identifiers, column names, table names, or other parts of the query.\ntools: search_products_by_category: kind: couchbase-sql source: my-couchbase-instance statement: | SELECT p.name, p.price, p.description FROM products p WHERE p.category = $category AND p.price \u003c $max_price ORDER BY p.price DESC LIMIT 10 description: | Use this tool to get a list of products for a specific category under a maximum price. Takes a category name, e.g. \"Electronics\" and a maximum price e.g 500 and returns a list of product names, prices, and descriptions. Do NOT use this tool with invalid category names. Do NOT guess a category name, Do NOT guess a price. Example: {{ \"category\": \"Electronics\", \"max_price\": 500 }} Example: {{ \"category\": \"Furniture\", \"max_price\": 1000 }} parameters: - name: category type: string description: Product category name - name: max_price type: integer description: Maximum price (positive integer) Example with Template Parameters Note: This tool allows direct modifications to the SQL statement, including identifiers, column names, and table names. This makes it more vulnerable to SQL injections. Using basic parameters only (see above) is recommended for performance and safety reasons. For more details, please check templateParameters.\ntools: list_table: kind: couchbase-sql source: my-couchbase-instance statement: | SELECT * FROM {{.tableName}}; description: | Use this tool to list all information from a specific table. Example: {{ \"tableName\": \"flights\", }} templateParameters: - name: tableName type: string description: Table to select from Reference field type required description kind string true Must be “couchbase-sql”. source string true Name of the source the SQL query should execute on. description string true Description of the tool that is passed to the LLM. statement string true SQL statement to execute parameters parameters false List of parameters that will be used with the SQL statement. templateParameters templateParameters false List of templateParameters that will be inserted into the SQL statement before executing prepared statement. authRequired array[string] false List of auth services that are required to use this tool. ","categories":"","description":"A \"couchbase-sql\" tool executes a pre-defined SQL statement against a Couchbase database.\n","excerpt":"A \"couchbase-sql\" tool executes a pre-defined SQL statement against a …","ref":"/genai-toolbox/resources/tools/couchbase/couchbase-sql/","tags":"","title":"couchbase-sql"},{"body":"About Dgraph is an open-source graph database. It is designed for real-time workloads, horizontal scalability, and data flexibility. Implemented as a distributed system, Dgraph processes queries in parallel to deliver the fastest result.\nThis source can connect to either a self-managed Dgraph cluster or one hosted on Dgraph Cloud. If you’re new to Dgraph, the fastest way to get started is to sign up for Dgraph Cloud.\nRequirements Database User When connecting to a hosted Dgraph database, this source uses the API key for access. If you are using a dedicated environment, you will additionally need the namespace and user credentials for that namespace.\nFor connecting to a local or self-hosted Dgraph database, use the namespace and user credentials for that namespace.\nExample sources: my-dgraph-source: kind: dgraph dgraphUrl: https://xxxx.cloud.dgraph.io user: ${USER_NAME} password: ${PASSWORD} apiKey: ${API_KEY} namespace : 0 Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nReference Field Type Required Description kind string true Must be “dgraph”. dgraphUrl string true Connection URI (e.g. “https://xxx.cloud.dgraph.io”, “https://localhost:8080”). user string false Name of the Dgraph user to connect as (e.g., “groot”). password string false Password of the Dgraph user (e.g., “password”). apiKey string false API key to connect to a Dgraph Cloud instance. namespace uint64 false Dgraph namespace (not required for Dgraph Cloud Shared Clusters). ","categories":"","description":"Dgraph is fully open-source, built-for-scale graph database for Gen AI workloads\n","excerpt":"Dgraph is fully open-source, built-for-scale graph database for Gen AI …","ref":"/genai-toolbox/resources/sources/dgraph/","tags":"","title":"Dgraph"},{"body":"","categories":"","description":"Tools that work with Dgraph Sources.\n","excerpt":"Tools that work with Dgraph Sources.\n","ref":"/genai-toolbox/resources/tools/dgraph/","tags":"","title":"Dgraph"},{"body":"About A dgraph-dql tool executes a pre-defined DQL statement against a Dgraph database. It’s compatible with any of the following sources:\ndgraph To run a statement as a query, you need to set the config isQuery=true. For upserts or mutations, set isQuery=false. You can also configure timeout for a query.\nNote: This tool uses parameterized queries to prevent SQL injections. Query parameters can be used as substitutes for arbitrary expressions. Parameters cannot be used as substitutes for identifiers, column names, table names, or other parts of the query.\nExample Query Mutation tools: search_user: kind: dgraph-dql source: my-dgraph-source statement: | query all($role: string){ users(func: has(name)) @filter(eq(role, $role) AND ge(age, 30) AND le(age, 50)) { uid name email role age } } isQuery: true timeout: 20s description: | Use this tool to retrieve the details of users who are admins and are between 30 and 50 years old. The query returns the user's name, email, role, and age. This can be helpful when you want to fetch admin users within a specific age range. Example: Fetch admins aged between 30 and 50: [ { \"name\": \"Alice\", \"role\": \"admin\", \"age\": 35 }, { \"name\": \"Bob\", \"role\": \"admin\", \"age\": 45 } ] parameters: - name: $role type: string description: admin tools: dgraph-manage-user-instance: kind: dgraph-dql source: my-dgraph-source isQuery: false statement: | { set { _:user1 \u003cname\u003e $user1 . _:user1 \u003cemail\u003e $email1 . _:user1 \u003crole\u003e \"admin\" . _:user1 \u003cage\u003e \"35\" . _:user2 \u003cname\u003e $user2 . _:user2 \u003cemail\u003e $email2 . _:user2 \u003crole\u003e \"admin\" . _:user2 \u003cage\u003e \"45\" . } } description: | Use this tool to insert or update user data into the Dgraph database. The mutation adds or updates user details like name, email, role, and age. Example: Add users Alice and Bob as admins with specific ages. parameters: - name: user1 type: string description: Alice - name: email1 type: string description: alice@email.com - name: user2 type: string description: Bob - name: email2 type: string description: bob@email.com Reference field type required description kind string true Must be “dgraph-dql”. source string true Name of the source the dql query should execute on. description string true Description of the tool that is passed to the LLM. statement string true dql statement to execute isQuery boolean false To run statement as query set true otherwise false timeout string false To set timeout for query parameters parameters false List of parameters that will be used with the dql statement. ","categories":"","description":"A \"dgraph-dql\" tool executes a pre-defined DQL statement against a Dgraph database.\n","excerpt":"A \"dgraph-dql\" tool executes a pre-defined DQL statement against a …","ref":"/genai-toolbox/resources/tools/dgraph/dgraph-dql/","tags":"","title":"dgraph-dql"},{"body":" ","categories":"","description":"All of Toolbox's documentation. \n","excerpt":"All of Toolbox's documentation. \n","ref":"/genai-toolbox/","tags":"","title":"Documentation"},{"body":"","categories":"","description":"How to get started with Toolbox.\n","excerpt":"How to get started with Toolbox.\n","ref":"/genai-toolbox/getting-started/","tags":"","title":"Getting Started"},{"body":"Getting Started Google Sign-In manages the OAuth 2.0 flow and token lifecycle. To integrate the Google Sign-In workflow to your web app follow this guide.\nAfter setting up the Google Sign-In workflow, you should have registered your application and retrieved a Client ID. Configure your auth service in with the Client ID.\nBehavior Authorized Invocations When using Authorized Invocations, a tool will be considered authorized if it has a valid Oauth 2.0 token that matches the Client ID.\nAuthenticated Parameters When using Authenticated Parameters, any claim provided by the id-token can be used for the parameter.\nExample authServices: my-google-auth: kind: google clientId: ${YOUR_GOOGLE_CLIENT_ID} Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nReference field type required description kind string true Must be “google”. clientId string true Client ID of your application from registering your application. ","categories":"","description":"Use Google Sign-In for Oauth 2.0 flow and token lifecycle. \n","excerpt":"Use Google Sign-In for Oauth 2.0 flow and token lifecycle. \n","ref":"/genai-toolbox/resources/authservices/google/","tags":"","title":"Google Sign-In"},{"body":"About The http tool allows you to make HTTP requests to APIs to retrieve data. An HTTP request is the method by which a client communicates with a server to retrieve or manipulate resources. Toolbox allows you to configure the request URL, method, headers, query parameters, and the request body for an HTTP Tool.\nURL An HTTP request URL identifies the target the client wants to access. Toolbox composes the request URL from 3 places:\nThe HTTP Source’s baseUrl. The HTTP Tool’s path field. The HTTP Tool’s pathParams for dynamic path composed during Tool invocation. For example, the following config allows you to reach different paths of the same server using multiple Tools:\nsources: my-http-source: kind: http baseUrl: https://api.example.com tools: my-post-tool: kind: http source: my-http-source method: POST path: /update description: Tool to update information to the example API my-get-tool: kind: http source: my-http-source method: GET path: /search description: Tool to search information from the example API my-dynamic-path-tool: kind: http source: my-http-source method: GET path: /{{.myPathParam}}/search description: Tool to reach endpoint based on the input to `myPathParam` pathParams: - name: myPathParam type: string description: The dynamic path parameter Headers An HTTP request header is a key-value pair sent by a client to a server, providing additional information about the request, such as the client’s preferences, the request body content type, and other metadata. Headers specified by the HTTP Tool are combined with its HTTP Source headers for the resulting HTTP request, and override the Source headers in case of conflict. The HTTP Tool allows you to specify headers in two different ways:\nStatic headers can be specified using the headers field, and will be the same for every invocation: my-http-tool: kind: http source: my-http-source method: GET path: /search description: Tool to search data from API headers: Authorization: API_KEY Content-Type: application/json Dynamic headers can be specified as parameters in the headerParams field. The name of the headerParams will be used as the header key, and the value is determined by the LLM input upon Tool invocation: my-http-tool: kind: http source: my-http-source method: GET path: /search description: some description headerParams: - name: Content-Type # Example LLM input: \"application/json\" description: request content type type: string Query parameters Query parameters are key-value pairs appended to a URL after a question mark (?) to provide additional information to the server for processing the request, like filtering or sorting data.\nStatic request query parameters should be specified in the path as part of the URL itself: my-http-tool: kind: http source: my-http-source method: GET path: /search?language=en\u0026id=1 description: Tool to search for item with ID 1 in English Dynamic request query parameters should be specified as parameters in the queryParams section: my-http-tool: kind: http source: my-http-source method: GET path: /search description: Tool to search for item with ID queryParams: - name: id description: item ID type: integer Request body The request body payload is a string that supports parameter replacement following Go template’s annotations. The parameter names in the requestBody should be preceded by “.” and enclosed by double curly brackets “{{}}”. The values will be populated into the request body payload upon Tool invocation.\nExample:\nmy-http-tool: kind: http source: my-http-source method: GET path: /search description: Tool to search for person with name and age requestBody: | { \"age\": {{.age}}, \"name\": \"{{.name}}\" } bodyParams: - name: age description: age number type: integer - name: name description: name string type: string Formatting Parameters Some complex parameters (such as arrays) may require additional formatting to match the expected output. For convenience, you can specify one of the following pre-defined functions before the parameter name to format it:\nJSON The json keyword converts a parameter into a JSON format.\nNote\nUsing JSON may add quotes to the variable name for certain types (such as strings).\nExample:\nrequestBody: | { \"age\": {{json .age}}, \"name\": {{json .name}}, \"nickname\": \"{{json .nickname}}\", \"nameArray\": {{json .nameArray}} } will send the following output:\n{ \"age\": 18, \"name\": \"Katherine\", \"nickname\": \"\"Kat\"\", # Duplicate quotes \"nameArray\": [\"A\", \"B\", \"C\"] } Example my-http-tool: kind: http source: my-http-source method: GET path: /search description: some description authRequired: - my-google-auth-service - other-auth-service queryParams: - name: country description: some description type: string requestBody: | { \"age\": {{.age}}, \"city\": \"{{.city}}\" } bodyParams: - name: age description: age number type: integer - name: city description: city string type: string headers: Authorization: API_KEY Content-Type: application/json headerParams: - name: Language description: language string type: string Reference field type required description kind string true Must be “http”. source string true Name of the source the HTTP request should be sent to. description string true Description of the tool that is passed to the LLM. path string true The path of the HTTP request. You can include static query parameters in the path string. method string true The HTTP method to use (e.g., GET, POST, PUT, DELETE). headers map[string]string false A map of headers to include in the HTTP request (overrides source headers). requestBody string false The request body payload. Use go template with the parameter name as the placeholder (e.g., {{.id}} will be replaced with the value of the parameter that has name id in the bodyParams section). queryParams parameters false List of parameters that will be inserted into the query string. bodyParams parameters false List of parameters that will be inserted into the request body payload. headerParams parameters false List of parameters that will be inserted as the request headers. ","categories":"","description":"A \"http\" tool sends out an HTTP request to an HTTP endpoint.\n","excerpt":"A \"http\" tool sends out an HTTP request to an HTTP endpoint.\n","ref":"/genai-toolbox/resources/tools/http/http/","tags":"","title":"http"},{"body":"About The HTTP Source allows Toolbox to retrieve data from arbitrary HTTP endpoints. This enables Generative AI applications to access data from web APIs and other HTTP-accessible resources.\nExample sources: my-http-source: kind: http baseUrl: https://api.example.com/data timeout: 10s # default to 30s headers: Authorization: Bearer ${API_KEY} Content-Type: application/json queryParams: param1: value1 param2: value2 # disableSslVerification: false Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nReference field type required description kind string true Must be “http”. baseUrl string true The base URL for the HTTP requests (e.g., https://api.example.com). timeout string false The timeout for HTTP requests (e.g., “5s”, “1m”, refer to ParseDuration for more examples). Defaults to 30s. headers map[string]string false Default headers to include in the HTTP requests. queryParams map[string]string false Default query parameters to include in the HTTP requests. disableSslVerification bool false Disable SSL certificate verification. This should only be used for local development. Defaults to false. ","categories":"","description":"The HTTP source enables the Toolbox to retrieve data from a remote server using HTTP requests.\n","excerpt":"The HTTP source enables the Toolbox to retrieve data from a remote …","ref":"/genai-toolbox/resources/sources/http/","tags":"","title":"HTTP"},{"body":"","categories":"","description":"Tools that work with HTTP Sources.\n","excerpt":"Tools that work with HTTP Sources.\n","ref":"/genai-toolbox/resources/tools/http/","tags":"","title":"HTTP"},{"body":"MCP Toolbox for Databases is an open source MCP server for databases. It enables you to develop tools easier, faster, and more securely by handling the complexities such as connection pooling, authentication, and more.\nNote\nThis solution was originally named “Gen AI Toolbox for Databases” as its initial development predated MCP, but was renamed to align with recently added MCP compatibility.\nWhy Toolbox? Toolbox helps you build Gen AI tools that let your agents access data in your database. Toolbox provides:\nSimplified development: Integrate tools to your agent in less than 10 lines of code, reuse tools between multiple agents or frameworks, and deploy new versions of tools more easily. Better performance: Best practices such as connection pooling, authentication, and more. Enhanced security: Integrated auth for more secure access to your data End-to-end observability: Out of the box metrics and tracing with built-in support for OpenTelemetry. ⚡ Supercharge Your Workflow with an AI Database Assistant ⚡\nStop context-switching and let your AI assistant become a true co-developer. By connecting your IDE to your databases with MCP Toolbox, you can delegate complex and time-consuming database tasks, allowing you to build faster and focus on what matters. This isn’t just about code completion; it’s about giving your AI the context it needs to handle the entire development lifecycle.\nHere’s how it will save you time:\nQuery in Plain English: Interact with your data using natural language right from your IDE. Ask complex questions like, “How many orders were delivered in 2024, and what items were in them?” without writing any SQL. Automate Database Management: Simply describe your data needs, and let the AI assistant manage your database for you. It can handle generating queries, creating tables, adding indexes, and more. Generate Context-Aware Code: Empower your AI assistant to generate application code and tests with a deep understanding of your real-time database schema. This accelerates the development cycle by ensuring the generated code is directly usable. Slash Development Overhead: Radically reduce the time spent on manual setup and boilerplate. MCP Toolbox helps streamline lengthy database configurations, repetitive code, and error-prone schema migrations. Learn how to connect your AI tools (IDEs) to Toolbox using MCP.\nGeneral Architecture Toolbox sits between your application’s orchestration framework and your database, providing a control plane that is used to modify, distribute, or invoke tools. It simplifies the management of your tools by providing you with a centralized location to store and update tools, allowing you to share tools between agents and applications and update those tools without necessarily redeploying your application.\nGetting Started Installing the server For the latest version, check the releases page and use the following instructions for your OS and CPU architecture.\nBinary Container image Compile from source To install Toolbox as a binary:\n# see releases page for other versions export VERSION=0.8.0 curl -O https://storage.googleapis.com/genai-toolbox/v$VERSION/linux/amd64/toolbox chmod +x toolbox You can also install Toolbox as a container:\n# see releases page for other versions export VERSION=0.8.0 docker pull us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:$VERSION To install from source, ensure you have the latest version of Go installed, and then run the following command:\ngo install github.com/googleapis/genai-toolbox@v0.8.0 Running the server Configure a tools.yaml to define your tools, and then execute toolbox to start the server:\n./toolbox --tools-file \"tools.yaml\" Note\nToolbox enables dynamic reloading by default. To disable, use the --disable-reload flag.\nYou can use toolbox help for a full list of flags! To stop the server, send a terminate signal (ctrl+c on most platforms).\nFor more detailed documentation on deploying to different environments, check out the resources in the How-to section\nIntegrating your application Once your server is up and running, you can load the tools into your application. See below the list of Client SDKs for using various frameworks:\nPython Core LangChain Llamaindex Once you’ve installed the Toolbox Core SDK, you can load tools:\nfrom toolbox_core import ToolboxClient # update the url to point to your server async with ToolboxClient(\"\u003chttp://127.0.0.1:5000\u003e\") as client: # these tools can be passed to your application! tools = await client.load_toolset(\"toolset_name\") For more detailed instructions on using the Toolbox Core SDK, see the project’s README.\nOnce you’ve installed the Toolbox LangChain SDK, you can load tools:\nfrom toolbox_langchain import ToolboxClient # update the url to point to your server async with ToolboxClient(\"\u003chttp://127.0.0.1:5000\u003e\") as client: # these tools can be passed to your application! tools = client.load_toolset() For more detailed instructions on using the Toolbox LangChain SDK, see the project’s README.\nOnce you’ve installed the Toolbox Llamaindex SDK, you can load tools:\nfrom toolbox_llamaindex import ToolboxClient # update the url to point to your server async with ToolboxClient(\"\u003chttp://127.0.0.1:5000\u003e\") as client: # these tools can be passed to your application tools = client.load_toolset() For more detailed instructions on using the Toolbox Llamaindex SDK, see the project’s README.\nJavascript/Typescript Once you’ve installed the Toolbox Core SDK, you can load tools:\nCore LangChain/Langraph Genkit LlamaIndex import { ToolboxClient } from '@toolbox-sdk/core'; // update the url to point to your server const URL = 'http://127.0.0.1:5000'; let client = new ToolboxClient(URL); // these tools can be passed to your application! const toolboxTools = await client.loadToolset('toolsetName'); import { ToolboxClient } from '@toolbox-sdk/core'; // update the url to point to your server const URL = 'http://127.0.0.1:5000'; let client = new ToolboxClient(URL); // these tools can be passed to your application! const toolboxTools = await client.loadToolset('toolsetName'); // Define the basics of the tool: name, description, schema and core logic const getTool = (toolboxTool) =\u003e tool(currTool, { name: toolboxTool.getName(), description: toolboxTool.getDescription(), schema: toolboxTool.getParamSchema() }); // Use these tools in your Langchain/Langraph applications const tools = toolboxTools.map(getTool); import { ToolboxClient } from '@toolbox-sdk/core'; import { genkit } from 'genkit'; // Initialise genkit const ai = genkit({ plugins: [ googleAI({ apiKey: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY }) ], model: googleAI.model('gemini-2.0-flash'), }); // update the url to point to your server const URL = 'http://127.0.0.1:5000'; let client = new ToolboxClient(URL); // these tools can be passed to your application! const toolboxTools = await client.loadToolset('toolsetName'); // Define the basics of the tool: name, description, schema and core logic const getTool = (toolboxTool) =\u003e ai.defineTool({ name: toolboxTool.getName(), description: toolboxTool.getDescription(), schema: toolboxTool.getParamSchema() }, toolboxTool) // Use these tools in your Genkit applications const tools = toolboxTools.map(getTool); import { ToolboxClient } from '@toolbox-sdk/core'; import { tool } from \"llamaindex\"; // update the url to point to your server const URL = 'http://127.0.0.1:5000'; let client = new ToolboxClient(URL); // these tools can be passed to your application! const toolboxTools = await client.loadToolset('toolsetName'); // Define the basics of the tool: name, description, schema and core logic const getTool = (toolboxTool) =\u003e tool({ name: toolboxTool.getName(), description: toolboxTool.getDescription(), parameters: toolboxTool.getParams(), execute: toolboxTool });; // Use these tools in your LlamaIndex applications const tools = toolboxTools.map(getTool); For more detailed instructions on using the Toolbox Core SDK, see the project’s README.\n","categories":"","description":"An introduction to MCP Toolbox for Databases.\n","excerpt":"An introduction to MCP Toolbox for Databases.\n","ref":"/genai-toolbox/getting-started/introduction/","tags":"","title":"Introduction"},{"body":"About A mssql-execute-sql tool executes a SQL statement against a SQL Server database. It’s compatible with any of the following sources:\ncloud-sql-mssql mssql mssql-execute-sql takes one input parameter sql and run the sql statement against the source.\nNote: This tool is intended for developer assistant workflows with human-in-the-loop and shouldn’t be used for production agents.\nExample tools: execute_sql_tool: kind: mssql-execute-sql source: my-mssql-instance description: Use this tool to execute sql statement. Reference field type required description kind string true Must be “mssql-execute-sql”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. ","categories":"","description":"A \"mssql-execute-sql\" tool executes a SQL statement against a SQL Server database.\n","excerpt":"A \"mssql-execute-sql\" tool executes a SQL statement against a SQL …","ref":"/genai-toolbox/resources/tools/mssql/mssql-execute-sql/","tags":"","title":"mssql-execute-sql"},{"body":"About A mssql-sql tool executes a pre-defined SQL statement against a SQL Server database. It’s compatible with any of the following sources:\ncloud-sql-mssql mssql Toolbox supports the prepare statement syntax of MS SQL Server and expects parameters in the SQL query to be in the form of either @Name or @p1 to @pN (ordinal position).\ndb.QueryContext(ctx, `select * from t where ID = @ID and Name = @p2;`, sql.Named(\"ID\", 6), \"Bob\") Example Note: This tool uses parameterized queries to prevent SQL injections. Query parameters can be used as substitutes for arbitrary expressions. Parameters cannot be used as substitutes for identifiers, column names, table names, or other parts of the query.\ntools: search_flights_by_number: kind: mssql-sql source: my-instance statement: | SELECT * FROM flights WHERE airline = @airline AND flight_number = @flight_number LIMIT 10 description: | Use this tool to get information for a specific flight. Takes an airline code and flight number and returns info on the flight. Do NOT use this tool with a flight id. Do NOT guess an airline code or flight number. A airline code is a code for an airline service consisting of two-character airline designator and followed by flight number, which is 1 to 4 digit number. For example, if given CY 0123, the airline is \"CY\", and flight_number is \"123\". Another example for this is DL 1234, the airline is \"DL\", and flight_number is \"1234\". If the tool returns more than one option choose the date closes to today. Example: {{ \"airline\": \"CY\", \"flight_number\": \"888\", }} Example: {{ \"airline\": \"DL\", \"flight_number\": \"1234\", }} parameters: - name: airline type: string description: Airline unique 2 letter identifier - name: flight_number type: string description: 1 to 4 digit number Example with Template Parameters Note: This tool allows direct modifications to the SQL statement, including identifiers, column names, and table names. This makes it more vulnerable to SQL injections. Using basic parameters only (see above) is recommended for performance and safety reasons. For more details, please check templateParameters.\ntools: list_table: kind: mssql-sql source: my-instance statement: | SELECT * FROM {{.tableName}}; description: | Use this tool to list all information from a specific table. Example: {{ \"tableName\": \"flights\", }} templateParameters: - name: tableName type: string description: Table to select from Reference field type required description kind string true Must be “mssql-sql”. source string true Name of the source the T-SQL statement should execute on. description string true Description of the tool that is passed to the LLM. statement string true SQL statement to execute. parameters parameters false List of parameters that will be inserted into the SQL statement. templateParameters templateParameters false List of templateParameters that will be inserted into the SQL statement before executing prepared statement. ","categories":"","description":"A \"mssql-sql\" tool executes a pre-defined SQL statement against a SQL Server database.\n","excerpt":"A \"mssql-sql\" tool executes a pre-defined SQL statement against a SQL …","ref":"/genai-toolbox/resources/tools/mssql/mssql-sql/","tags":"","title":"mssql-sql"},{"body":"About MySQL is a relational database management system (RDBMS) that stores and manages data. It’s a popular choice for developers because of its reliability, performance, and ease of use.\nRequirements Database User This source only uses standard authentication. You will need to create a MySQL user to login to the database with.\nExample sources: my-mysql-source: kind: mysql host: 127.0.0.1 port: 3306 database: my_db user: ${USER_NAME} password: ${PASSWORD} queryTimeout: 30s # Optional: query timeout duration Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nReference field type required description kind string true Must be “mysql”. host string true IP address to connect to (e.g. “127.0.0.1”). port string true Port to connect to (e.g. “3306”). database string true Name of the MySQL database to connect to (e.g. “my_db”). user string true Name of the MySQL user to connect as (e.g. “my-mysql-user”). password string true Password of the MySQL user (e.g. “my-password”). queryTimeout string false Maximum time to wait for query execution (e.g. “30s”, “2m”). By default, no timeout is applied. ","categories":"","description":"MySQL is a relational database management system that stores and manages data.\n","excerpt":"MySQL is a relational database management system that stores and …","ref":"/genai-toolbox/resources/sources/mysql/","tags":"","title":"MySQL"},{"body":"","categories":"","description":"Tools that work with MySQL Sources, such as Cloud SQL for MySQL.\n","excerpt":"Tools that work with MySQL Sources, such as Cloud SQL for MySQL.\n","ref":"/genai-toolbox/resources/tools/mysql/","tags":"","title":"MySQL"},{"body":"About A mysql-execute-sql tool executes a SQL statement against a MySQL database. It’s compatible with any of the following sources:\ncloud-sql-mysql mysql mysql-execute-sql takes one input parameter sql and run the sql statement against the source.\nNote: This tool is intended for developer assistant workflows with human-in-the-loop and shouldn’t be used for production agents.\nExample tools: execute_sql_tool: kind: mysql-execute-sql source: my-mysql-instance description: Use this tool to execute sql statement. Reference field type required description kind string true Must be “mysql-execute-sql”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. ","categories":"","description":"A \"mysql-execute-sql\" tool executes a SQL statement against a MySQL database.\n","excerpt":"A \"mysql-execute-sql\" tool executes a SQL statement against a MySQL …","ref":"/genai-toolbox/resources/tools/mysql/mysql-execute-sql/","tags":"","title":"mysql-execute-sql"},{"body":"About A mysql-sql tool executes a pre-defined SQL statement against a MySQL database. It’s compatible with any of the following sources:\ncloud-sql-mysql mysql The specified SQL statement is executed as a prepared statement, and expects parameters in the SQL query to be in the form of placeholders ?.\nExample Note: This tool uses parameterized queries to prevent SQL injections. Query parameters can be used as substitutes for arbitrary expressions. Parameters cannot be used as substitutes for identifiers, column names, table names, or other parts of the query.\ntools: search_flights_by_number: kind: mysql-sql source: my-mysql-instance statement: | SELECT * FROM flights WHERE airline = ? AND flight_number = ? LIMIT 10 description: | Use this tool to get information for a specific flight. Takes an airline code and flight number and returns info on the flight. Do NOT use this tool with a flight id. Do NOT guess an airline code or flight number. A airline code is a code for an airline service consisting of two-character airline designator and followed by flight number, which is 1 to 4 digit number. For example, if given CY 0123, the airline is \"CY\", and flight_number is \"123\". Another example for this is DL 1234, the airline is \"DL\", and flight_number is \"1234\". If the tool returns more than one option choose the date closes to today. Example: {{ \"airline\": \"CY\", \"flight_number\": \"888\", }} Example: {{ \"airline\": \"DL\", \"flight_number\": \"1234\", }} parameters: - name: airline type: string description: Airline unique 2 letter identifier - name: flight_number type: string description: 1 to 4 digit number Example with Template Parameters Note: This tool allows direct modifications to the SQL statement, including identifiers, column names, and table names. This makes it more vulnerable to SQL injections. Using basic parameters only (see above) is recommended for performance and safety reasons. For more details, please check templateParameters.\ntools: list_table: kind: mysql-sql source: my-mysql-instance statement: | SELECT * FROM {{.tableName}}; description: | Use this tool to list all information from a specific table. Example: {{ \"tableName\": \"flights\", }} templateParameters: - name: tableName type: string description: Table to select from Reference field type required description kind string true Must be “mysql-sql”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. statement string true SQL statement to execute on. parameters parameters false List of parameters that will be inserted into the SQL statement. templateParameters templateParameters false List of templateParameters that will be inserted into the SQL statement before executing prepared statement. ","categories":"","description":"A \"mysql-sql\" tool executes a pre-defined SQL statement against a MySQL database.\n","excerpt":"A \"mysql-sql\" tool executes a pre-defined SQL statement against a …","ref":"/genai-toolbox/resources/tools/mysql/mysql-sql/","tags":"","title":"mysql-sql"},{"body":"Neo4j is a powerful, open source graph database system with over 15 years of active development that has earned it a strong reputation for reliability, feature robustness, and performance.\nRequirements Database User This source only uses standard authentication. You will need to create a Neo4j user to log in to the database with, or use the default neo4j user if available.\nExample sources: my-neo4j-source: kind: neo4j uri: neo4j+s://xxxx.databases.neo4j.io:7687 user: ${USER_NAME} password: ${PASSWORD} database: \"neo4j\" Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nReference field type required description kind string true Must be “neo4j”. uri string true Connect URI (“bolt://localhost”, “neo4j+s://xxx.databases.neo4j.io”) user string true Name of the Neo4j user to connect as (e.g. “neo4j”). password string true Password of the Neo4j user (e.g. “my-password”). database string true Name of the Neo4j database to connect to (e.g. “neo4j”). ","categories":"","description":"Neo4j is a powerful, open source graph database system\n","excerpt":"Neo4j is a powerful, open source graph database system\n","ref":"/genai-toolbox/resources/sources/neo4j/","tags":"","title":"Neo4j"},{"body":"","categories":"","description":"Tools that work with Neo4j Sources.\n","excerpt":"Tools that work with Neo4j Sources.\n","ref":"/genai-toolbox/resources/tools/neo4j/","tags":"","title":"Neo4j"},{"body":"About A neo4j-cypher tool executes a pre-defined Cypher statement against a Neo4j database. It’s compatible with any of the following sources:\nneo4j The specified Cypher statement is executed as a parameterized statement, and specified parameters will be used according to their name: e.g. $id.\nNote: This tool uses parameterized queries to prevent SQL injections. Query parameters can be used as substitutes for arbitrary expressions. Parameters cannot be used as substitutes for identifiers, column names, table names, or other parts of the query.\nExample tools: search_movies_by_actor: kind: neo4j-cypher source: my-neo4j-movies-instance statement: | MATCH (m:Movie)\u003c-[:ACTED_IN]-(p:Person) WHERE p.name = $name AND m.year \u003e $year RETURN m.title, m.year LIMIT 10 description: | Use this tool to get a list of movies for a specific actor and a given minimum release year. Takes an full actor name, e.g. \"Tom Hanks\" and a year e.g 1993 and returns a list of movie titles and release years. Do NOT use this tool with a movie title. Do NOT guess an actor name, Do NOT guess a year. A actor name is a fully qualified name with first and last name separated by a space. For example, if given \"Hanks, Tom\" the actor name is \"Tom Hanks\". If the tool returns more than one option choose the most recent movies. Example: {{ \"name\": \"Meg Ryan\", \"year\": 1993 }} Example: {{ \"name\": \"Clint Eastwood\", \"year\": 2000 }} parameters: - name: name type: string description: Full actor name, \"firstname lastname\" - name: year type: integer description: 4 digit number starting in 1900 up to the current year Reference field type required description kind string true Must be “neo4j-cypher”. source string true Name of the source the Cypher query should execute on. description string true Description of the tool that is passed to the LLM. statement string true Cypher statement to execute parameters parameters false List of parameters that will be used with the Cypher statement. ","categories":"","description":"A \"neo4j-cypher\" tool executes a pre-defined cypher statement against a Neo4j database.\n","excerpt":"A \"neo4j-cypher\" tool executes a pre-defined cypher statement against …","ref":"/genai-toolbox/resources/tools/neo4j/neo4j-cypher/","tags":"","title":"neo4j-cypher"},{"body":"About OceanBase is a distributed relational database management system (RDBMS) that provides high availability, scalability, and strong consistency. It’s designed to handle large-scale data processing and is compatible with MySQL, making it easy for developers to migrate from MySQL to OceanBase.\nRequirements Database User This source only uses standard authentication. You will need to create an OceanBase user to login to the database with. OceanBase supports MySQL-compatible user management syntax.\nNetwork Connectivity Ensure that your application can connect to the OceanBase cluster. OceanBase typically runs on ports 2881 (for MySQL protocol) or 3881 (for MySQL protocol with SSL).\nExample sources: my-oceanbase-source: kind: oceanbase host: 127.0.0.1 port: 2881 database: my_db user: ${USER_NAME} password: ${PASSWORD} queryTimeout: 30s # Optional: query timeout duration Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nReference field type required description kind string true Must be “oceanbase”. host string true IP address to connect to (e.g. “127.0.0.1”). port string true Port to connect to (e.g. “2881”). database string true Name of the OceanBase database to connect to (e.g. “my_db”). user string true Name of the OceanBase user to connect as (e.g. “my-oceanbase-user”). password string true Password of the OceanBase user (e.g. “my-password”). queryTimeout string false Maximum time to wait for query execution (e.g. “30s”, “2m”). By default, no timeout is applied. Features MySQL Compatibility OceanBase is highly compatible with MySQL, supporting most MySQL SQL syntax, data types, and functions. This makes it easy to migrate existing MySQL applications to OceanBase.\nHigh Availability OceanBase provides automatic failover and data replication across multiple nodes, ensuring high availability and data durability.\nScalability OceanBase can scale horizontally by adding more nodes to the cluster, making it suitable for large-scale applications.\nStrong Consistency OceanBase provides strong consistency guarantees, ensuring that all transactions are ACID compliant.\n","categories":"","description":"OceanBase is a distributed relational database that provides high availability, scalability, and compatibility with MySQL.\n","excerpt":"OceanBase is a distributed relational database that provides high …","ref":"/genai-toolbox/resources/sources/oceanbase/","tags":"","title":"OceanBase"},{"body":"","categories":"","description":"Tools that work with OceanBase Sources.\n","excerpt":"Tools that work with OceanBase Sources.\n","ref":"/genai-toolbox/resources/tools/oceanbase/","tags":"","title":"OceanBase"},{"body":"About An oceanbase-execute-sql tool executes a SQL statement against an OceanBase database. It’s compatible with the following source:\noceanbase oceanbase-execute-sql takes one input parameter sql and runs the sql statement against the source.\nNote: This tool is intended for developer assistant workflows with human-in-the-loop and shouldn’t be used for production agents.\nExample tools: execute_sql_tool: kind: oceanbase-execute-sql source: my-oceanbase-instance description: Use this tool to execute sql statement. Reference field type required description kind string true Must be “oceanbase-execute-sql”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. ","categories":"","description":"An \"oceanbase-execute-sql\" tool executes a SQL statement against an OceanBase database.\n","excerpt":"An \"oceanbase-execute-sql\" tool executes a SQL statement against an …","ref":"/genai-toolbox/resources/tools/oceanbase/oceanbase-execute-sql/","tags":"","title":"oceanbase-execute-sql"},{"body":"About An oceanbase-sql tool executes a pre-defined SQL statement against an OceanBase database. It’s compatible with the following source:\noceanbase The specified SQL statement is executed as a prepared statement, and expects parameters in the SQL query to be in the form of placeholders ?.\nExample Note: This tool uses parameterized queries to prevent SQL injections. Query parameters can be used as substitutes for arbitrary expressions. Parameters cannot be used as substitutes for identifiers, column names, table names, or other parts of the query.\ntools: search_flights_by_number: kind: oceanbase-sql source: my-oceanbase-instance statement: | SELECT * FROM flights WHERE airline = ? AND flight_number = ? LIMIT 10 description: | Use this tool to get information for a specific flight. Takes an airline code and flight number and returns info on the flight. Do NOT use this tool with a flight id. Do NOT guess an airline code or flight number. Example: {{ \"airline\": \"CY\", \"flight_number\": \"888\", }} parameters: - name: airline type: string description: Airline unique 2 letter identifier - name: flight_number type: string description: 1 to 4 digit number Example with Template Parameters Note: This tool allows direct modifications to the SQL statement, including identifiers, column names, and table names. This makes it more vulnerable to SQL injections. Using basic parameters only (see above) is recommended for performance and safety reasons.\ntools: list_table: kind: oceanbase-sql source: my-oceanbase-instance statement: | SELECT * FROM {{.tableName}}; description: | Use this tool to list all information from a specific table. Example: {{ \"tableName\": \"flights\", }} templateParameters: - name: tableName type: string description: Table to select from Example with Array Parameters tools: search_flights_by_ids: kind: oceanbase-sql source: my-oceanbase-instance statement: | SELECT * FROM flights WHERE id IN (?) AND status IN (?) description: | Use this tool to get information for multiple flights by their IDs and statuses. Example: {{ \"flight_ids\": [1, 2, 3], \"statuses\": [\"active\", \"scheduled\"] }} parameters: - name: flight_ids type: array description: List of flight IDs to search for items: name: flight_id type: integer description: Individual flight ID - name: statuses type: array description: List of flight statuses to filter by items: name: status type: string description: Individual flight status Reference field type required description kind string true Must be “oceanbase-sql”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. statement string true SQL statement to execute on. parameters parameters false List of parameters that will be inserted into the SQL statement. templateParameters templateParameters false List of templateParameters that will be inserted into the SQL statement before executing prepared statement. ","categories":"","description":"An \"oceanbase-sql\" tool executes a pre-defined SQL statement against an OceanBase database.\n","excerpt":"An \"oceanbase-sql\" tool executes a pre-defined SQL statement against …","ref":"/genai-toolbox/resources/tools/oceanbase/oceanbase-sql/","tags":"","title":"oceanbase-sql"},{"body":"","categories":"","description":"Tools that work with Postgres Sources, such as Cloud SQL for Postgres and AlloyDB. \n","excerpt":"Tools that work with Postgres Sources, such as Cloud SQL for Postgres …","ref":"/genai-toolbox/resources/tools/postgres/","tags":"","title":"Postgres"},{"body":"About A postgres-execute-sql tool executes a SQL statement against a Postgres database. It’s compatible with any of the following sources:\nalloydb-postgres cloud-sql-postgres postgres postgres-execute-sql takes one input parameter sql and run the sql statement against the source.\nNote: This tool is intended for developer assistant workflows with human-in-the-loop and shouldn’t be used for production agents.\nExample tools: execute_sql_tool: kind: postgres-execute-sql source: my-pg-instance description: Use this tool to execute sql statement. Reference field type required description kind string true Must be “postgres-execute-sql”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. ","categories":"","description":"A \"postgres-execute-sql\" tool executes a SQL statement against a Postgres database.\n","excerpt":"A \"postgres-execute-sql\" tool executes a SQL statement against a …","ref":"/genai-toolbox/resources/tools/postgres/postgres-execute-sql/","tags":"","title":"postgres-execute-sql"},{"body":"About A postgres-sql tool executes a pre-defined SQL statement against a Postgres database. It’s compatible with any of the following sources:\nalloydb-postgres cloud-sql-postgres postgres The specified SQL statement is executed as a prepared statement, and specified parameters will inserted according to their position: e.g. 1 will be the first parameter specified, $@ will be the second parameter, and so on. If template parameters are included, they will be resolved before execution of the prepared statement.\nExample Note: This tool uses parameterized queries to prevent SQL injections. Query parameters can be used as substitutes for arbitrary expressions. Parameters cannot be used as substitutes for identifiers, column names, table names, or other parts of the query.\ntools: search_flights_by_number: kind: postgres-sql source: my-pg-instance statement: | SELECT * FROM flights WHERE airline = $1 AND flight_number = $2 LIMIT 10 description: | Use this tool to get information for a specific flight. Takes an airline code and flight number and returns info on the flight. Do NOT use this tool with a flight id. Do NOT guess an airline code or flight number. A airline code is a code for an airline service consisting of two-character airline designator and followed by flight number, which is 1 to 4 digit number. For example, if given CY 0123, the airline is \"CY\", and flight_number is \"123\". Another example for this is DL 1234, the airline is \"DL\", and flight_number is \"1234\". If the tool returns more than one option choose the date closes to today. Example: {{ \"airline\": \"CY\", \"flight_number\": \"888\", }} Example: {{ \"airline\": \"DL\", \"flight_number\": \"1234\", }} parameters: - name: airline type: string description: Airline unique 2 letter identifier - name: flight_number type: string description: 1 to 4 digit number Example with Template Parameters Note: This tool allows direct modifications to the SQL statement, including identifiers, column names, and table names. This makes it more vulnerable to SQL injections. Using basic parameters only (see above) is recommended for performance and safety reasons. For more details, please check templateParameters.\ntools: list_table: kind: postgres-sql source: my-pg-instance statement: | SELECT * FROM {{.tableName}} description: | Use this tool to list all information from a specific table. Example: {{ \"tableName\": \"flights\", }} templateParameters: - name: tableName type: string description: Table to select from Reference field type required description kind string true Must be “postgres-sql”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. statement string true SQL statement to execute on. parameters parameters false List of parameters that will be inserted into the SQL statement. templateParameters templateParameters false List of templateParameters that will be inserted into the SQL statement before executing prepared statement. ","categories":"","description":"A \"postgres-sql\" tool executes a pre-defined SQL statement against a Postgres database.\n","excerpt":"A \"postgres-sql\" tool executes a pre-defined SQL statement against a …","ref":"/genai-toolbox/resources/tools/postgres/postgres-sql/","tags":"","title":"postgres-sql"},{"body":"About PostgreSQL is a powerful, open source object-relational database system with over 35 years of active development that has earned it a strong reputation for reliability, feature robustness, and performance.\nRequirements Database User This source only uses standard authentication. You will need to create a PostgreSQL user to login to the database with.\nExample sources: my-pg-source: kind: postgres host: 127.0.0.1 port: 5432 database: my_db user: ${USER_NAME} password: ${PASSWORD} Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nReference field type required description kind string true Must be “postgres”. host string true IP address to connect to (e.g. “127.0.0.1”) port string true Port to connect to (e.g. “5432”) database string true Name of the Postgres database to connect to (e.g. “my_db”). user string true Name of the Postgres user to connect as (e.g. “my-pg-user”). password string true Password of the Postgres user (e.g. “my-password”). ","categories":"","description":"PostgreSQL is a powerful, open source object-relational database.\n","excerpt":"PostgreSQL is a powerful, open source object-relational database.\n","ref":"/genai-toolbox/resources/sources/postgres/","tags":"","title":"PostgreSQL"},{"body":"\nBefore you begin This guide assumes you have already done the following:\nInstalled Python 3.9+ (including pip and your preferred virtual environment tool for managing dependencies e.g. venv).\nInstalled and configured the Google Cloud SDK (gcloud CLI).\nAuthenticated with Google Cloud for Application Default Credentials (ADC):\ngcloud auth login --update-adc Set your default Google Cloud project (replace YOUR_PROJECT_ID with your actual project ID):\ngcloud config set project YOUR_PROJECT_ID export GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_ID Toolbox and the client libraries will use this project for BigQuery, unless overridden in configurations.\nEnabled the BigQuery API in your Google Cloud project.\nInstalled the BigQuery client library for Python:\npip install google-cloud-bigquery Completed setup for usage with an LLM model such as Core LangChain LlamaIndex ADK langchain-vertexai package.\nlangchain-google-genai package.\nlangchain-anthropic package.\nlangchain-vertexai package.\nlangchain-google-genai package.\nlangchain-anthropic package.\nllama-index-llms-google-genai package.\nllama-index-llms-anthropic package.\ngoogle-adk package. Step 1: Set up your BigQuery Dataset and Table In this section, we will create a BigQuery dataset and a table, then insert some data that needs to be accessed by our agent. BigQuery operations are performed against your configured Google Cloud project.\nCreate a new BigQuery dataset (replace YOUR_DATASET_NAME with your desired dataset name, e.g., toolbox_ds, and optionally specify a location like US or EU):\nexport BQ_DATASET_NAME=\"YOUR_DATASET_NAME\" # e.g., toolbox_ds export BQ_LOCATION=\"US\" # e.g., US, EU, asia-northeast1 bq --location=$BQ_LOCATION mk $BQ_DATASET_NAME You can also do this through the Google Cloud Console.\nTip\nFor a real application, ensure that the service account or user running Toolbox has the necessary IAM permissions (e.g., BigQuery Data Editor, BigQuery User) on the dataset or project. For this local quickstart with user credentials, your own permissions will apply.\nThe hotels table needs to be defined in your new dataset for use with the bq query command. First, create a file named create_hotels_table.sql with the following content:\nCREATE TABLE IF NOT EXISTS `YOUR_PROJECT_ID.YOUR_DATASET_NAME.hotels` ( id INT64 NOT NULL, name STRING NOT NULL, location STRING NOT NULL, price_tier STRING NOT NULL, checkin_date DATE NOT NULL, checkout_date DATE NOT NULL, booked BOOLEAN NOT NULL ); Note: Replace YOUR_PROJECT_ID and YOUR_DATASET_NAME in the SQL with your actual project ID and dataset name.\nThen run the command below to execute the sql query:\nbq query --project_id=$GOOGLE_CLOUD_PROJECT --dataset_id=$BQ_DATASET_NAME --use_legacy_sql=false \u003c create_hotels_table.sql Next, populate the hotels table with some initial data. To do this, create a file named insert_hotels_data.sql and add the following SQL INSERT statement to it.\nINSERT INTO `YOUR_PROJECT_ID.YOUR_DATASET_NAME.hotels` (id, name, location, price_tier, checkin_date, checkout_date, booked) VALUES (1, 'Hilton Basel', 'Basel', 'Luxury', '2024-04-20', '2024-04-22', FALSE), (2, 'Marriott Zurich', 'Zurich', 'Upscale', '2024-04-14', '2024-04-21', FALSE), (3, 'Hyatt Regency Basel', 'Basel', 'Upper Upscale', '2024-04-02', '2024-04-20', FALSE), (4, 'Radisson Blu Lucerne', 'Lucerne', 'Midscale', '2024-04-05', '2024-04-24', FALSE), (5, 'Best Western Bern', 'Bern', 'Upper Midscale', '2024-04-01', '2024-04-23', FALSE), (6, 'InterContinental Geneva', 'Geneva', 'Luxury', '2024-04-23', '2024-04-28', FALSE), (7, 'Sheraton Zurich', 'Zurich', 'Upper Upscale', '2024-04-02', '2024-04-27', FALSE), (8, 'Holiday Inn Basel', 'Basel', 'Upper Midscale', '2024-04-09', '2024-04-24', FALSE), (9, 'Courtyard Zurich', 'Zurich', 'Upscale', '2024-04-03', '2024-04-13', FALSE), (10, 'Comfort Inn Bern', 'Bern', 'Midscale', '2024-04-04', '2024-04-16', FALSE); Note: Replace YOUR_PROJECT_ID and YOUR_DATASET_NAME in the SQL with your actual project ID and dataset name.\nThen run the command below to execute the sql query:\nbq query --project_id=$GOOGLE_CLOUD_PROJECT --dataset_id=$BQ_DATASET_NAME --use_legacy_sql=false \u003c insert_hotels_data.sql Step 2: Install and configure Toolbox In this section, we will download Toolbox, configure our tools in a tools.yaml to use BigQuery, and then run the Toolbox server.\nDownload the latest version of Toolbox as a binary:\nTip\nSelect the correct binary corresponding to your OS and CPU architecture.\nexport OS=\"linux/amd64\" # one of linux/amd64, darwin/arm64, darwin/amd64, or windows/amd64 curl -O https://storage.googleapis.com/genai-toolbox/v0.8.0/$OS/toolbox Make the binary executable:\nchmod +x toolbox Write the following into a tools.yaml file. You must replace the YOUR_PROJECT_ID and YOUR_DATASET_NAME placeholder in the config with your actual BigQuery project and dataset name. The location field is optional; if not specified, it defaults to ‘us’. The table name hotels is used directly in the statements.\nTip\nAuthentication with BigQuery is handled via Application Default Credentials (ADC). Ensure you have run gcloud auth application-default login.\nsources: my-bigquery-source: kind: bigquery project: YOUR_PROJECT_ID location: us tools: search-hotels-by-name: kind: bigquery-sql source: my-bigquery-source description: Search for hotels based on name. parameters: - name: name type: string description: The name of the hotel. statement: SELECT * FROM `YOUR_DATASET_NAME.hotels` WHERE LOWER(name) LIKE LOWER(CONCAT('%', @name, '%')); search-hotels-by-location: kind: bigquery-sql source: my-bigquery-source description: Search for hotels based on location. parameters: - name: location type: string description: The location of the hotel. statement: SELECT * FROM `YOUR_DATASET_NAME.hotels` WHERE LOWER(location) LIKE LOWER(CONCAT('%', @location, '%')); book-hotel: kind: bigquery-sql source: my-bigquery-source description: \u003e- Book a hotel by its ID. If the hotel is successfully booked, returns a NULL, raises an error if not. parameters: - name: hotel_id type: integer description: The ID of the hotel to book. statement: UPDATE `YOUR_DATASET_NAME.hotels` SET booked = TRUE WHERE id = @hotel_id; update-hotel: kind: bigquery-sql source: my-bigquery-source description: \u003e- Update a hotel's check-in and check-out dates by its ID. Returns a message indicating whether the hotel was successfully updated or not. parameters: - name: checkin_date type: string description: The new check-in date of the hotel. - name: checkout_date type: string description: The new check-out date of the hotel. - name: hotel_id type: integer description: The ID of the hotel to update. statement: \u003e- UPDATE `YOUR_DATASET_NAME.hotels` SET checkin_date = PARSE_DATE('%Y-%m-%d', @checkin_date), checkout_date = PARSE_DATE('%Y-%m-%d', @checkout_date) WHERE id = @hotel_id; cancel-hotel: kind: bigquery-sql source: my-bigquery-source description: Cancel a hotel by its ID. parameters: - name: hotel_id type: integer description: The ID of the hotel to cancel. statement: UPDATE `YOUR_DATASET_NAME.hotels` SET booked = FALSE WHERE id = @hotel_id; Important Note on toolsets: The tools.yaml content above does not include a toolsets section. The Python agent examples in Step 3 (e.g., await toolbox_client.load_toolset(\"my-toolset\")) rely on a toolset named my-toolset. To make those examples work, you will need to add a toolsets section to your tools.yaml file, for example:\n# Add this to your tools.yaml if using load_toolset(\"my-toolset\") # Ensure it's at the same indentation level as 'sources:' and 'tools:' toolsets: my-toolset: - search-hotels-by-name - search-hotels-by-location - book-hotel - update-hotel - cancel-hotel Alternatively, you can modify the agent code to load tools individually (e.g., using await toolbox_client.load_tool(\"search-hotels-by-name\")).\nFor more info on tools, check out the Resources section of the docs.\nRun the Toolbox server, pointing to the tools.yaml file created earlier:\n./toolbox --tools-file \"tools.yaml\" Note\nToolbox enables dynamic reloading by default. To disable, use the `--disable-reload` flag. Step 3: Connect your agent to Toolbox In this section, we will write and run an agent that will load the Tools from Toolbox.\nTip\nIf you prefer to experiment within a Google Colab environment, you can connect to a local runtime.\nIn a new terminal, install the SDK package.\nCore Langchain LlamaIndex ADK pip install toolbox-core pip install toolbox-langchain pip install toolbox-llamaindex pip install google-adk Install other required dependencies:\nCore Langchain LlamaIndex ADK # TODO(developer): replace with correct package if needed pip install langgraph langchain-google-vertexai # pip install langchain-google-genai # pip install langchain-anthropic # TODO(developer): replace with correct package if needed pip install langgraph langchain-google-vertexai # pip install langchain-google-genai # pip install langchain-anthropic # TODO(developer): replace with correct package if needed pip install llama-index-llms-google-genai # pip install llama-index-llms-anthropic pip install toolbox-core Create a new file named hotel_agent.py and copy the following code to create an agent: Core LangChain LlamaIndex ADK import asyncio from google import genai from google.genai.types import ( Content, FunctionDeclaration, GenerateContentConfig, Part, Tool, ) from toolbox_core import ToolboxClient prompt = \"\"\" You're a helpful hotel assistant. You handle hotel searching, booking and cancellations. When the user searches for a hotel, mention it's name, id, location and price tier. Always mention hotel id while performing any searches. This is very important for any operations. For any bookings or cancellations, please provide the appropriate confirmation. Be sure to update checkin or checkout dates if mentioned by the user. Don't ask for confirmations from the user. \"\"\" queries = [ \"Find hotels in Basel with Basel in it's name.\", \"Please book the hotel Hilton Basel for me.\", \"This is too expensive. Please cancel it.\", \"Please book Hyatt Regency for me\", \"My check in dates for my booking would be from April 10, 2024 to April 19, 2024.\", ] async def run_application(): async with ToolboxClient(\"\u003chttp://127.0.0.1:5000\u003e\") as toolbox_client: # The toolbox_tools list contains Python callables (functions/methods) designed for LLM tool-use # integration. While this example uses Google's genai client, these callables can be adapted for # various function-calling or agent frameworks. For easier integration with supported frameworks # (https://github.com/googleapis/mcp-toolbox-python-sdk/tree/main/packages), use the # provided wrapper packages, which handle framework-specific boilerplate. toolbox_tools = await toolbox_client.load_toolset(\"my-toolset\") genai_client = genai.Client( vertexai=True, project=\"project-id\", location=\"us-central1\" ) genai_tools = [ Tool( function_declarations=[ FunctionDeclaration.from_callable_with_api_option(callable=tool) ] ) for tool in toolbox_tools ] history = [] for query in queries: user_prompt_content = Content( role=\"user\", parts=[Part.from_text(text=query)], ) history.append(user_prompt_content) response = genai_client.models.generate_content( model=\"gemini-2.0-flash-001\", contents=history, config=GenerateContentConfig( system_instruction=prompt, tools=genai_tools, ), ) history.append(response.candidates[0].content) function_response_parts = [] for function_call in response.function_calls: fn_name = function_call.name # The tools are sorted alphabetically if fn_name == \"search-hotels-by-name\": function_result = await toolbox_tools[3](**function_call.args) elif fn_name == \"search-hotels-by-location\": function_result = await toolbox_tools[2](**function_call.args) elif fn_name == \"book-hotel\": function_result = await toolbox_tools[0](**function_call.args) elif fn_name == \"update-hotel\": function_result = await toolbox_tools[4](**function_call.args) elif fn_name == \"cancel-hotel\": function_result = await toolbox_tools[1](**function_call.args) else: raise ValueError(\"Function name not present.\") function_response = {\"result\": function_result} function_response_part = Part.from_function_response( name=function_call.name, response=function_response, ) function_response_parts.append(function_response_part) if function_response_parts: tool_response_content = Content(role=\"tool\", parts=function_response_parts) history.append(tool_response_content) response2 = genai_client.models.generate_content( model=\"gemini-2.0-flash-001\", contents=history, config=GenerateContentConfig( tools=genai_tools, ), ) final_model_response_content = response2.candidates[0].content history.append(final_model_response_content) print(response2.text) asyncio.run(run_application()) import asyncio from langgraph.prebuilt import create_react_agent # TODO(developer): replace this with another import if needed from langchain_google_vertexai import ChatVertexAI # from langchain_google_genai import ChatGoogleGenerativeAI # from langchain_anthropic import ChatAnthropic from langgraph.checkpoint.memory import MemorySaver from toolbox_langchain import ToolboxClient prompt = \"\"\" You're a helpful hotel assistant. You handle hotel searching, booking and cancellations. When the user searches for a hotel, mention it's name, id, location and price tier. Always mention hotel ids while performing any searches. This is very important for any operations. For any bookings or cancellations, please provide the appropriate confirmation. Be sure to update checkin or checkout dates if mentioned by the user. Don't ask for confirmations from the user. \"\"\" queries = [ \"Find hotels in Basel with Basel in it's name.\", \"Can you book the Hilton Basel for me?\", \"Oh wait, this is too expensive. Please cancel it and book the Hyatt Regency instead.\", \"My check in dates would be from April 10, 2024 to April 19, 2024.\", ] async def main(): # TODO(developer): replace this with another model if needed model = ChatVertexAI(model_name=\"gemini-2.0-flash-001\") # model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\") # model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\") # Load the tools from the Toolbox server client = ToolboxClient(\"http://127.0.0.1:5000\") tools = await client.aload_toolset() agent = create_react_agent(model, tools, checkpointer=MemorySaver()) config = {\"configurable\": {\"thread_id\": \"thread-1\"}} for query in queries: inputs = {\"messages\": [(\"user\", prompt + query)]} response = await agent.ainvoke(inputs, stream_mode=\"values\", config=config) print(response[\"messages\"][-1].content) asyncio.run(main()) import asyncio import os from llama_index.core.agent.workflow import AgentWorkflow from llama_index.core.workflow import Context # TODO(developer): replace this with another import if needed from llama_index.llms.google_genai import GoogleGenAI # from llama_index.llms.anthropic import Anthropic from toolbox_llamaindex import ToolboxClient prompt = \"\"\" You're a helpful hotel assistant. You handle hotel searching, booking and cancellations. When the user searches for a hotel, mention it's name, id, location and price tier. Always mention hotel ids while performing any searches. This is very important for any operations. For any bookings or cancellations, please provide the appropriate confirmation. Be sure to update checkin or checkout dates if mentioned by the user. Don't ask for confirmations from the user. \"\"\" queries = [ \"Find hotels in Basel with Basel in it's name.\", \"Can you book the Hilton Basel for me?\", \"Oh wait, this is too expensive. Please cancel it and book the Hyatt Regency instead.\", \"My check in dates would be from April 10, 2024 to April 19, 2024.\", ] async def main(): # TODO(developer): replace this with another model if needed llm = GoogleGenAI( model=\"gemini-2.0-flash-001\", vertexai_config={\"location\": \"us-central1\"}, ) # llm = GoogleGenAI( # api_key=os.getenv(\"GOOGLE_API_KEY\"), # model=\"gemini-2.0-flash-001\", # ) # llm = Anthropic( # model=\"claude-3-7-sonnet-latest\", # api_key=os.getenv(\"ANTHROPIC_API_KEY\") # ) # Load the tools from the Toolbox server client = ToolboxClient(\"http://127.0.0.1:5000\") tools = await client.aload_toolset() agent = AgentWorkflow.from_tools_or_functions( tools, llm=llm, system_prompt=prompt, ) ctx = Context(agent) for query in queries: response = await agent.arun(user_msg=query, ctx=ctx) print(f\"---- {query} ----\") print(str(response)) asyncio.run(main()) from google.adk.agents import Agent from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.adk.artifacts.in_memory_artifact_service import InMemoryArtifactService from google.genai import types # For constructing message content from toolbox_core import ToolboxSyncClient import os os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = 'True' # TODO(developer): Replace 'YOUR_PROJECT_ID' with your Google Cloud Project ID os.environ['GOOGLE_CLOUD_PROJECT'] = 'YOUR_PROJECT_ID' # TODO(developer): Replace 'us-central1' with your Google Cloud Location (region) os.environ['GOOGLE_CLOUD_LOCATION'] = 'us-central1' # --- Load Tools from Toolbox --- # TODO(developer): Ensure the Toolbox server is running at \u003chttp://127.0.0.1:5000\u003e with ToolboxSyncClient(\"\u003chttp://127.0.0.1:5000\u003e\") as toolbox_client: # TODO(developer): Replace \"my-toolset\" with the actual ID of your toolset as configured in your MCP Toolbox server. agent_toolset = toolbox_client.load_toolset(\"my-toolset\") # --- Define the Agent's Prompt --- prompt = \"\"\" You're a helpful hotel assistant. You handle hotel searching, booking and cancellations. When the user searches for a hotel, mention it's name, id, location and price tier. Always mention hotel ids while performing any searches. This is very important for any operations. For any bookings or cancellations, please provide the appropriate confirmation. Be sure to update checkin or checkout dates if mentioned by the user. Don't ask for confirmations from the user. \"\"\" # --- Configure the Agent --- root_agent = Agent( model='gemini-2.0-flash-001', name='hotel_agent', description='A helpful AI assistant that can search and book hotels.', instruction=prompt, tools=agent_toolset, # Pass the loaded toolset ) # --- Initialize Services for Running the Agent --- session_service = InMemorySessionService() artifacts_service = InMemoryArtifactService() # Create a new session for the interaction. session = session_service.create_session( state={}, app_name='hotel_agent', user_id='123' ) runner = Runner( app_name='hotel_agent', agent=root_agent, artifact_service=artifacts_service, session_service=session_service, ) # --- Define Queries and Run the Agent --- queries = [ \"Find hotels in Basel with Basel in it's name.\", \"Can you book the Hilton Basel for me?\", \"Oh wait, this is too expensive. Please cancel it and book the Hyatt Regency instead.\", \"My check in dates would be from April 10, 2024 to April 19, 2024.\", ] for query in queries: content = types.Content(role='user', parts=[types.Part(text=query)]) events = runner.run(session_id=session.id, user_id='123', new_message=content) responses = ( part.text for event in events for part in event.content.parts if part.text is not None ) for text in responses: print(text) Core Langchain LlamaIndex ADK To learn more about the Core SDK, check out the Toolbox Core SDK documentation.\nTo learn more about Agents in LangChain, check out the LangGraph Agent documentation.\nTo learn more about Agents in LlamaIndex, check out the LlamaIndex AgentWorkflow documentation.\nTo learn more about Agents in ADK, check out the ADK documentation.\nRun your agent, and observe the results:\npython hotel_agent.py ","categories":"","description":"How to get started running Toolbox locally with Python, BigQuery, and  LangGraph, LlamaIndex, or ADK.\n","excerpt":"How to get started running Toolbox locally with Python, BigQuery, and …","ref":"/genai-toolbox/samples/bigquery/local_quickstart/","tags":"","title":"Quickstart (Local with BigQuery)"},{"body":"About A redis tool executes a series of pre-defined Redis commands against a Redis source.\nThe specified Redis commands are executed sequentially. Each command is represented as a string list, where the first element is the command name (e.g., SET, GET, HGETALL) and subsequent elements are its arguments.\nDynamic Command Parameters Command arguments can be templated using the $variableName annotation. The array type parameters will be expanded once into multiple arguments. Take the following config for example:\ncommands: - [SADD, userNames, $userNames] # Array will be flattened into multiple arguments. parameters: - name: userNames type: array description: The user names to be set. If the input is an array of strings [\"Alice\", \"Sid\", \"Bob\"], The final command to be executed after argument expansion will be [SADD, userNames, Alice, Sid, Bob].\nExample tools: user_data_tool: kind: redis source: my-redis-instance description: | Use this tool to interact with user data stored in Redis. It can set, retrieve, and delete user-specific information. commands: - [SADD, userNames, $userNames] # Array will be flattened into multiple arguments. - [GET, $userId] parameters: - name: userId type: string description: The unique identifier for the user. - name: userNames type: array description: The user names to be set. ","categories":"","description":"A \"redis\" tool executes a set of pre-defined Redis commands against a Redis instance.\n","excerpt":"A \"redis\" tool executes a set of pre-defined Redis commands against a …","ref":"/genai-toolbox/resources/tools/redis/redis/","tags":"","title":"redis"},{"body":"About Redis is an open-source, in-memory data structure store, used as a database, cache, and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs, and geospatial indexes with radius queries.\nIf you are new to Redis, you can find installation and getting started guides on the official Redis website.\nRequirements Redis AUTH string is a password for connection to Redis. If you have the requirepass directive set in your Redis configuration, incoming client connections must authenticate in order to connect.\nSpecify your AUTH string in the password field:\nsources: my-redis-instance: kind: redis address: - 127.0.0.1 username: ${MY_USER_NAME} password: ${MY_AUTH_STRING} # Omit this field if you don't have a password. # database: 0 # clusterEnabled: false # useGCPIAM: false Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nMemorystore For Redis Memorystore standalone instances support authentication using an AUTH string.\nHere is an example tools.yaml config with AUTH enabled:\nsources: my-redis-cluster-instance: kind: memorystore-redis address: - 127.0.0.1 password: ${MY_AUTH_STRING} # useGCPIAM: false # clusterEnabled: false Memorystore Redis Cluster supports IAM authentication instead. Grant your account the required IAM role and make sure to set useGCPIAM to true.\nHere is an example tools.yaml config for Memorystore Redis Cluster instances using IAM authentication:\nsources: my-redis-cluster-instance: kind: memorystore-redis address: 127.0.0.1 useGCPIAM: true clusterEnabled: true Reference field type required description kind string true Must be “memorystore-redis”. address string true Primary endpoint for the Memorystore Redis instance to connect to. username string false If you are using a non-default user, specify the user name here. If you are using Memorystore for Redis, leave this field blank password string false If you have Redis AUTH enabled, specify the AUTH string here database int false The Redis database to connect to. Not applicable for cluster enabled instances. The default database is 0. clusterEnabled bool false Set it to true if using a Redis Cluster instance. Defaults to false. useGCPIAM string false Set it to true if you are using GCP’s IAM authentication. Defaults to false. ","categories":"","description":"Redis is an open-source, in-memory data structure store.\n","excerpt":"Redis is an open-source, in-memory data structure store.\n","ref":"/genai-toolbox/resources/sources/redis/","tags":"","title":"Redis"},{"body":"","categories":"","description":"Tools that work with Redis Sources.\n","excerpt":"Tools that work with Redis Sources.\n","ref":"/genai-toolbox/resources/tools/redis/","tags":"","title":"Redis"},{"body":"A Source represents a data sources that a tool can interact with. You can define Sources as a map in the sources section of your tools.yaml file. Typically, a source configuration will contain any information needed to connect with and interact with the database.\nTip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nsources: my-cloud-sql-source: kind: cloud-sql-postgres project: my-project-id region: us-central1 instance: my-instance-name database: my_db user: ${USER_NAME} password: ${PASSWORD} In implementation, each source is a different connection pool or client that used to connect to the database and execute the tool.\nAvailable Sources ","categories":"","description":"Sources represent your different data sources that a tool can interact with.\n","excerpt":"Sources represent your different data sources that a tool can interact …","ref":"/genai-toolbox/resources/sources/","tags":"","title":"Sources"},{"body":"Spanner Source Spanner is a fully managed, mission-critical database service that brings together relational, graph, key-value, and search. It offers transactional consistency at global scale, automatic, synchronous replication for high availability, and support for two SQL dialects: GoogleSQL (ANSI 2011 with extensions) and PostgreSQL.\nIf you are new to Spanner, you can try to create and query a database using the Google Cloud console.\nRequirements IAM Permissions Spanner uses Identity and Access Management (IAM) to control user and group access to Spanner resources at the project, Spanner instance, and Spanner database levels. Toolbox will use your Application Default Credentials (ADC) to authorize and authenticate when interacting with Spanner.\nIn addition to setting the ADC for your server, you need to ensure the IAM identity has been given the correct IAM permissions for the query provided. See Apply IAM roles for more information on applying IAM permissions and roles to an identity.\nExample sources: my-spanner-source: kind: \"spanner\" project: \"my-project-id\" instance: \"my-instance\" database: \"my_db\" # dialect: \"googlesql\" Reference field type required description kind string true Must be “spanner”. project string true Id of the GCP project that the cluster was created in (e.g. “my-project-id”). instance string true Name of the Spanner instance. database string true Name of the database on the Spanner instance dialect string false Name of the dialect type of the Spanner database, must be either googlesql or postgresql. Default: googlesql. ","categories":"","description":"Spanner is a fully managed database service from Google Cloud that combines  relational, key-value, graph, and search capabilities.\n","excerpt":"Spanner is a fully managed database service from Google Cloud that …","ref":"/genai-toolbox/resources/sources/spanner/","tags":"","title":"Spanner"},{"body":"","categories":"","description":"Tools that work with Spanner Sources.\n","excerpt":"Tools that work with Spanner Sources.\n","ref":"/genai-toolbox/resources/tools/spanner/","tags":"","title":"Spanner"},{"body":"About A spanner-execute-sql tool executes a SQL statement against a Spanner database. It’s compatible with any of the following sources:\nspanner spanner-execute-sql takes one input parameter sql and run the sql statement against the source.\nNote: This tool is intended for developer assistant workflows with human-in-the-loop and shouldn’t be used for production agents.\nExample tools: execute_sql_tool: kind: spanner-execute-sql source: my-spanner-instance description: Use this tool to execute sql statement. Reference field type required description kind string true Must be “spanner-execute-sql”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. readOnly bool false When set to true, the statement is run as a read-only transaction. Default: false. ","categories":"","description":"A \"spanner-execute-sql\" tool executes a SQL statement against a Spanner database.\n","excerpt":"A \"spanner-execute-sql\" tool executes a SQL statement against a …","ref":"/genai-toolbox/resources/tools/spanner/spanner-execute-sql/","tags":"","title":"spanner-execute-sql"},{"body":"About A spanner-sql tool executes a pre-defined SQL statement (either googlesql or postgresql) against a Cloud Spanner database. It’s compatible with any of the following sources:\nspanner GoogleSQL For the googlesql dialect, the specified SQL statement is executed as a data manipulation language (DML) statements, and specified parameters will inserted according to their name: e.g. @name.\nNote: This tool uses parameterized queries to prevent SQL injections. Query parameters can be used as substitutes for arbitrary expressions. Parameters cannot be used as substitutes for identifiers, column names, table names, or other parts of the query.\nPostgreSQL For the postgresql dialect, the specified SQL statement is executed as a prepared statement, and specified parameters will inserted according to their position: e.g. $1 will be the first parameter specified, $@ will be the second parameter, and so on.\nExample Note: This tool uses parameterized queries to prevent SQL injections. Query parameters can be used as substitutes for arbitrary expressions. Parameters cannot be used as substitutes for identifiers, column names, table names, or other parts of the query.\nGoogleSQL PostgreSQL tools: search_flights_by_number: kind: spanner-sql source: my-spanner-instance statement: | SELECT * FROM flights WHERE airline = @airline AND flight_number = @flight_number LIMIT 10 description: | Use this tool to get information for a specific flight. Takes an airline code and flight number and returns info on the flight. Do NOT use this tool with a flight id. Do NOT guess an airline code or flight number. A airline code is a code for an airline service consisting of two-character airline designator and followed by flight number, which is 1 to 4 digit number. For example, if given CY 0123, the airline is \"CY\", and flight_number is \"123\". Another example for this is DL 1234, the airline is \"DL\", and flight_number is \"1234\". If the tool returns more than one option choose the date closes to today. Example: {{ \"airline\": \"CY\", \"flight_number\": \"888\", }} Example: {{ \"airline\": \"DL\", \"flight_number\": \"1234\", }} parameters: - name: airline type: string description: Airline unique 2 letter identifier - name: flight_number type: string description: 1 to 4 digit number tools: search_flights_by_number: kind: spanner source: my-spanner-instance statement: | SELECT * FROM flights WHERE airline = $1 AND flight_number = $2 LIMIT 10 description: | Use this tool to get information for a specific flight. Takes an airline code and flight number and returns info on the flight. Do NOT use this tool with a flight id. Do NOT guess an airline code or flight number. A airline code is a code for an airline service consisting of two-character airline designator and followed by flight number, which is 1 to 4 digit number. For example, if given CY 0123, the airline is \"CY\", and flight_number is \"123\". Another example for this is DL 1234, the airline is \"DL\", and flight_number is \"1234\". If the tool returns more than one option choose the date closes to today. Example: {{ \"airline\": \"CY\", \"flight_number\": \"888\", }} Example: {{ \"airline\": \"DL\", \"flight_number\": \"1234\", }} parameters: - name: airline type: string description: Airline unique 2 letter identifier - name: flight_number type: string description: 1 to 4 digit number Example with Template Parameters Note: This tool allows direct modifications to the SQL statement, including identifiers, column names, and table names. This makes it more vulnerable to SQL injections. Using basic parameters only (see above) is recommended for performance and safety reasons. For more details, please check templateParameters.\ntools: list_table: kind: spanner source: my-spanner-instance statement: | SELECT * FROM {{.tableName}}; description: | Use this tool to list all information from a specific table. Example: {{ \"tableName\": \"flights\", }} templateParameters: - name: tableName type: string description: Table to select from Reference field type required description kind string true Must be “spanner-sql”. source string true Name of the source the SQL should execute on. description string true Description of the tool that is passed to the LLM. statement string true SQL statement to execute on. parameters parameters false List of parameters that will be inserted into the SQL statement. readOnly bool false When set to true, the statement is run as a read-only transaction. Default: false. templateParameters templateParameters false List of templateParameters that will be inserted into the SQL statement before executing prepared statement. ","categories":"","description":"A \"spanner-sql\" tool executes a pre-defined SQL statement against a Google  Cloud Spanner database.\n","excerpt":"A \"spanner-sql\" tool executes a pre-defined SQL statement against a …","ref":"/genai-toolbox/resources/tools/spanner/spanner-sql/","tags":"","title":"spanner-sql"},{"body":"About SQL Server is a relational database management system (RDBMS) developed by Microsoft that allows users to store, retrieve, and manage large amount of data through a structured format.\nRequirements Database User This source only uses standard authentication. You will need to create a SQL Server user to login to the database with.\nExample sources: my-mssql-source: kind: mssql host: 127.0.0.1 port: 1433 database: my_db user: ${USER_NAME} password: ${PASSWORD} Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nReference field type required description kind string true Must be “mssql”. host string true IP address to connect to (e.g. “127.0.0.1”). port string true Port to connect to (e.g. “1433”). database string true Name of the SQL Server database to connect to (e.g. “my_db”). user string true Name of the SQL Server user to connect as (e.g. “my-user”). password string true Password of the SQL Server user (e.g. “my-password”). ","categories":"","description":"SQL Server is a relational database management system (RDBMS).\n","excerpt":"SQL Server is a relational database management system (RDBMS).\n","ref":"/genai-toolbox/resources/sources/mssql/","tags":"","title":"SQL Server"},{"body":"","categories":"","description":"Tools that work with SQL Server Sources, such as CloudSQL for SQL Server.\n","excerpt":"Tools that work with SQL Server Sources, such as CloudSQL for SQL …","ref":"/genai-toolbox/resources/tools/mssql/","tags":"","title":"SQL Server"},{"body":"About SQLite is a software library that provides a relational database management system. The lite in SQLite means lightweight in terms of setup, database administration, and required resources.\nSQLite has the following notable characteristics:\nSelf-contained with no external dependencies Serverless - the SQLite library accesses its storage files directly Single database file that can be easily copied or moved Zero-configuration - no setup or administration needed Transactional with ACID properties Requirements Database File You need a SQLite database file. This can be:\nAn existing database file A path where a new database file should be created :memory: for an in-memory database Example sources: my-sqlite-db: kind: \"sqlite\" database: \"/path/to/database.db\" For an in-memory database:\nsources: my-sqlite-memory-db: kind: \"sqlite\" database: \":memory:\" Reference Configuration Fields field type required description kind string true Must be “spanner”. database string true Path to SQLite database file, or “:memory:” for an in-memory database. Connection Properties SQLite connections are configured with these defaults for optimal performance:\nMaxOpenConns: 1 (SQLite only supports one writer at a time) MaxIdleConns: 1 ","categories":"","description":"SQLite is a C-language library that implements a small, fast, self-contained,  high-reliability, full-featured, SQL database engine.\n","excerpt":"SQLite is a C-language library that implements a small, fast, …","ref":"/genai-toolbox/resources/sources/sqlite/","tags":"","title":"SQLite"},{"body":"","categories":"","description":"Tools that work with SQLite Sources.\n","excerpt":"Tools that work with SQLite Sources.\n","ref":"/genai-toolbox/resources/tools/sqlite/","tags":"","title":"SQLite"},{"body":"About A sqlite-sql tool executes SQL statements against a SQLite database. It’s compatible with any of the following sources:\nsqlite SQLite uses the ? placeholder for parameters in SQL statements. Parameters are bound in the order they are provided.\nThe statement field supports any valid SQLite SQL statement, including SELECT, INSERT, UPDATE, DELETE, CREATE/ALTER/DROP table statements, and other DDL statements.\nExample Note: This tool uses parameterized queries to prevent SQL injections. Query parameters can be used as substitutes for arbitrary expressions. Parameters cannot be used as substitutes for identifiers, column names, table names, or other parts of the query.\ntools: search-users: kind: sqlite-sql source: my-sqlite-db description: Search users by name and age parameters: - name: name type: string description: The name to search for - name: min_age type: integer description: Minimum age statement: SELECT * FROM users WHERE name LIKE ? AND age \u003e= ? Example with Template Parameters Note: This tool allows direct modifications to the SQL statement, including identifiers, column names, and table names. This makes it more vulnerable to SQL injections. Using basic parameters only (see above) is recommended for performance and safety reasons. For more details, please check templateParameters.\ntools: list_table: kind: sqlite-sql source: my-sqlite-db statement: | SELECT * FROM {{.tableName}}; description: | Use this tool to list all information from a specific table. Example: {{ \"tableName\": \"flights\", }} templateParameters: - name: tableName type: string description: Table to select from Reference field type required description kind string true Must be “sqlite-sql”. source string true Name of the source the SQLite source configuration. description string true Description of the tool that is passed to the LLM. statement string true The SQL statement to execute. parameters parameters false List of parameters that will be inserted into the SQL statement. templateParameters templateParameters false List of templateParameters that will be inserted into the SQL statement before executing prepared statement. ","categories":"","description":"Execute SQL statements against a SQLite database.\n","excerpt":"Execute SQL statements against a SQLite database.\n","ref":"/genai-toolbox/resources/tools/sqlite/sqlite-sql/","tags":"","title":"sqlite-sql"},{"body":"About A valkey tool executes a series of pre-defined Valkey commands against a Memorystore for Valkey instance.\nThe specified Valkey commands are executed sequentially. Each command is represented as a string array, where the first element is the command name (e.g., SET, GET, HGETALL) and subsequent elements are its arguments.\nDynamic Command Parameters Command arguments can be templated using the $variableName annotation. The array type parameters will be expanded once into multiple arguments. Take the following config for example:\ncommands: - [SADD, userNames, $userNames] # Array will be flattened into multiple arguments. parameters: - name: userNames type: array description: The user names to be set. If the input is an array of strings [\"Alice\", \"Sid\", \"Bob\"], The final command to be executed after argument expansion will be [SADD, userNames, Alice, Sid, Bob].\nExample tools: user_data_tool: kind: valkey source: my-valkey-instance description: | Use this tool to interact with user data stored in Valkey. It can set, retrieve, and delete user-specific information. commands: - [SADD, userNames, $userNames] # Array will be flattened into multiple arguments. - [GET, $userId] parameters: - name: userId type: string description: The unique identifier for the user. - name: userNames type: array description: The user names to be set. ","categories":"","description":"A \"valkey\" tool executes a set of pre-defined Valkey commands against a Memorystore for Valkey instance.\n","excerpt":"A \"valkey\" tool executes a set of pre-defined Valkey commands against …","ref":"/genai-toolbox/resources/tools/valkey/valkey/","tags":"","title":"valkey"},{"body":"About Valkey is an open-source, in-memory data structure store that originated as a fork of Redis. It’s designed to be used as a database, cache, and message broker, supporting a wide range of data structures like strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs, and geospatial indexes with radius queries.\nIf you’re new to Valkey, you can find installation and getting started guides on the official Valkey website.\nExample sources: my-valkey-instance: kind: valkey address: - 127.0.0.1 username: ${YOUR_USERNAME} password: ${YOUR_PASSWORD} # database: 0 # useGCPIAM: false # disableCache: false Tip\nUse environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nIAM Authentication If you are using GCP’s Memorystore for Valkey, you can connect using IAM authentication. Grant your account the required IAM role and set useGCPIAM to true:\nsources: my-valkey-instance: kind: valkey address: - 127.0.0.1 useGCPIAM: true Reference field type required description kind string true Must be “valkey”. address []string true Endpoints for the Valkey instance to connect to. username string false If you are using a non-default user, specify the user name here. If you are using Memorystore for Valkey, leave this field blank password string false Password for the Valkey instance database int false The Valkey database to connect to. Not applicable for cluster enabled instances. The default database is 0. useGCPIAM bool false Set it to true if you are using GCP’s IAM authentication. Defaults to false. disableCache bool false Set it to true if you want to enable client-side caching. Defaults to false. ","categories":"","description":"Valkey is an open-source, in-memory data structure store, forked from Redis.\n","excerpt":"Valkey is an open-source, in-memory data structure store, forked from …","ref":"/genai-toolbox/resources/sources/valkey/","tags":"","title":"Valkey"},{"body":"","categories":"","description":"Tools that work with Valkey Sources.\n","excerpt":"Tools that work with Valkey Sources.\n","ref":"/genai-toolbox/resources/tools/valkey/","tags":"","title":"Valkey"},{"body":" ","categories":"","description":"Connect your IDE to AlloyDB using Toolbox.\n","excerpt":"Connect your IDE to AlloyDB using Toolbox.\n","ref":"/genai-toolbox/how-to/connect-ide/alloydb_pg_mcp/","tags":"","title":"AlloyDB using MCP"},{"body":" ","categories":"","description":"Connect your IDE to BigQuery using Toolbox.\n","excerpt":"Connect your IDE to BigQuery using Toolbox.\n","ref":"/genai-toolbox/how-to/connect-ide/bigquery_mcp/","tags":"","title":"BigQuery using MCP"},{"body":" ","categories":"","description":"Connect your IDE to Cloud SQL for MySQL using Toolbox.\n","excerpt":"Connect your IDE to Cloud SQL for MySQL using Toolbox.\n","ref":"/genai-toolbox/how-to/connect-ide/cloud_sql_mysql_mcp/","tags":"","title":"Cloud SQL for MySQL using MCP"},{"body":" ","categories":"","description":"Connect your IDE to Cloud SQL for Postgres using Toolbox.\n","excerpt":"Connect your IDE to Cloud SQL for Postgres using Toolbox.\n","ref":"/genai-toolbox/how-to/connect-ide/cloud_sql_pg_mcp/","tags":"","title":"Cloud SQL for Postgres using MCP"},{"body":" ","categories":"","description":"Connect your IDE to Cloud SQL for SQL Server using Toolbox.\n","excerpt":"Connect your IDE to Cloud SQL for SQL Server using Toolbox.\n","ref":"/genai-toolbox/how-to/connect-ide/cloud_sql_mssql_mcp/","tags":"","title":"Cloud SQL for SQL Server using MCP"},{"body":"","categories":"","description":"Some core concepts in Toolbox\n","excerpt":"Some core concepts in Toolbox\n","ref":"/genai-toolbox/concepts/","tags":"","title":"Concepts"},{"body":"How can I deploy or run Toolbox? MCP Toolbox for Databases is open-source and can be ran or deployed to a multitude of environments. For convenience, we release compiled binaries and docker images (but you can always compile yourself as well!).\nFor detailed instructions, check our these resources:\nQuickstart: How to Run Locally Deploy to Cloud Run Do I need a Google Cloud account/project to get started with Toolbox? Nope! While some of the sources Toolbox connects to may require GCP credentials, Toolbox doesn’t require them and can connect to a bunch of different resources that don’t.\nDoes Toolbox take contributions from external users? Absolutely! Please check out our DEVELOPER.md for instructions on how to get started developing on Toolbox instead of with it, and the CONTRIBUTING.md for instructions on completing the CLA and getting a PR accepted.\nCan Toolbox support a feature to let me do $FOO? Maybe? The best place to start is by opening an issue for discussion (or seeing if there is already one open), so we can better understand your use case and the best way to solve it. Generally we aim to prioritize the most popular issues, so make sure to +1 ones you are the most interested in.\nCan Toolbox be used for non-database tools? Currently, Toolbox is primarily focused on making it easier to create and develop tools focused on interacting with Databases. We believe that there are a lot of unique problems when interacting with Databases for Gen AI use cases, and want to prioritize solving those first.\nHowever, we’ve also received feedback that supporting more generic HTTP or GRPC tools might be helpful in assisting with migrating to Toolbox or in accomplishing more complicated workflows. We’re looking into what that might best look like in Toolbox.\nCan I use $BAR orchestration framework to use tools from Toolbox? Currently, Toolbox only supports a limited number of client SDKs at our initial launch. We are investigating support for more frameworks as well as more general approaches for users without a framework – look forward to seeing an update soon.\nWhy does Toolbox use a server-client architecture pattern? Toolbox’s server-client architecture allows us to more easily support a wide variety of languages and frameworks with a centralized implementation. It also allows us to tackle problems like connection pooling, auth, or caching more completely than entirely client-side solutions.\nWhy was Toolbox written in Go? While a large part of the Gen AI Ecosystem is predominately Python, we opted to use Go. We chose Go because it’s still easy and simple to use, but also easier to write fast, efficient, and concurrent servers. Additionally, given the server-client architecture, we can still meet many developers where they are with clients in their preferred language. As Gen AI matures, we want developers to be able to use Toolbox on the serving path of mission critical applications. It’s easier to build the needed robustness, performance and scalability in Go than in Python.\nIs Toolbox compatible with Model Context Protocol (MCP)? Yes! Toolbox is compatible with Anthropic’s Model Context Protocol (MCP). Please checkout Connect via MCP on how to connect to Toolbox with an MCP client.\n","categories":"","description":"Frequently asked questions about Toolbox.","excerpt":"Frequently asked questions about Toolbox.","ref":"/genai-toolbox/about/faq/","tags":"","title":"FAQ"},{"body":"","categories":"","description":"Go lang client SDK","excerpt":"Go lang client SDK","ref":"/genai-toolbox/sdks/go-sdk/","tags":"","title":"Go SDK"},{"body":"","categories":"","description":"Javascript client SDK","excerpt":"Javascript client SDK","ref":"/genai-toolbox/sdks/js-sdk/","tags":"","title":"JS SDK"},{"body":"Model Context Protocol (MCP) is an open protocol for connecting Large Language Models (LLMs) to data sources like Postgres. This guide covers how to use MCP Toolbox for Databases to expose your developer assistant tools to a Postgres instance:\nCursor Windsurf (Codium) Visual Studio Code (Copilot) Cline (VS Code extension) Claude desktop Claude code Tip\nThis guide can be used with AlloyDB Omni.\nSet up the database Create or select a PostgreSQL instance.\nInstall PostgreSQL locally Install AlloyDB Omni Create or reuse a database user and have the username and password ready.\nInstall MCP Toolbox Download the latest version of Toolbox as a binary. Select the correct binary corresponding to your OS and CPU architecture. You are required to use Toolbox version V0.6.0+:\nlinux/amd64 darwin/arm64 darwin/amd64 windows/amd64 curl -O \u003chttps://storage.googleapis.com/genai-toolbox/v0.8.0/linux/amd64/toolbox\u003e curl -O \u003chttps://storage.googleapis.com/genai-toolbox/v0.8.0/darwin/arm64/toolbox\u003e curl -O \u003chttps://storage.googleapis.com/genai-toolbox/v0.8.0/darwin/amd64/toolbox\u003e curl -O \u003chttps://storage.googleapis.com/genai-toolbox/v0.8.0/windows/amd64/toolbox\u003e Make the binary executable:\nchmod +x toolbox Verify the installation:\n./toolbox --version Configure your MCP Client Claude code Claude desktop Cline Cursor Visual Studio Code (Copilot) Windsurf Install Claude Code.\nCreate a .mcp.json file in your project root if it doesn’t exist.\nAdd the following configuration, replace the environment variables with your values, and save:\n{ \"mcpServers\": { \"postgres\": { \"command\": \"./PATH/TO/toolbox\", \"args\": [\"--prebuilt\",\"postgres\",\"--stdio\"], \"env\": { \"POSTGRES_HOST\": \"\", \"POSTGRES_PORT\": \"\", \"POSTGRES_DATABASE\": \"\", \"POSTGRES_USER\": \"\", \"POSTGRES_PASSWORD\": \"\" } } } } Restart Claude code to apply the new configuration.\nOpen Claude desktop and navigate to Settings.\nUnder the Developer tab, tap Edit Config to open the configuration file.\nAdd the following configuration, replace the environment variables with your values, and save:\n{ \"mcpServers\": { \"postgres\": { \"command\": \"./PATH/TO/toolbox\", \"args\": [\"--prebuilt\",\"postgres\",\"--stdio\"], \"env\": { \"POSTGRES_HOST\": \"\", \"POSTGRES_PORT\": \"\", \"POSTGRES_DATABASE\": \"\", \"POSTGRES_USER\": \"\", \"POSTGRES_PASSWORD\": \"\" } } } } Restart Claude desktop.\nFrom the new chat screen, you should see a hammer (MCP) icon appear with the new MCP server available.\nOpen the Cline extension in VS Code and tap the MCP Servers icon.\nTap Configure MCP Servers to open the configuration file.\nAdd the following configuration, replace the environment variables with your values, and save:\n{ \"mcpServers\": { \"postgres\": { \"command\": \"./PATH/TO/toolbox\", \"args\": [\"--prebuilt\",\"postgres\",\"--stdio\"], \"env\": { \"POSTGRES_HOST\": \"\", \"POSTGRES_PORT\": \"\", \"POSTGRES_DATABASE\": \"\", \"POSTGRES_USER\": \"\", \"POSTGRES_PASSWORD\": \"\" } } } } You should see a green active status after the server is successfully connected.\nCreate a .cursor directory in your project root if it doesn’t exist.\nCreate a .cursor/mcp.json file if it doesn’t exist and open it.\nAdd the following configuration, replace the environment variables with your values, and save:\n{ \"mcpServers\": { \"postgres\": { \"command\": \"./PATH/TO/toolbox\", \"args\": [\"--prebuilt\",\"postgres\",\"--stdio\"], \"env\": { \"POSTGRES_HOST\": \"\", \"POSTGRES_PORT\": \"\", \"POSTGRES_DATABASE\": \"\", \"POSTGRES_USER\": \"\", \"POSTGRES_PASSWORD\": \"\" } } } } Cursor and navigate to Settings \u003e Cursor Settings \u003e MCP. You should see a green active status after the server is successfully connected.\nOpen VS Code and create a .vscode directory in your project root if it doesn’t exist.\nCreate a .vscode/mcp.json file if it doesn’t exist and open it.\nAdd the following configuration, replace the environment variables with your values, and save:\n{ \"mcpServers\": { \"postgres\": { \"command\": \"./PATH/TO/toolbox\", \"args\": [\"--prebuilt\",\"postgres\",\"--stdio\"], \"env\": { \"POSTGRES_HOST\": \"\", \"POSTGRES_PORT\": \"\", \"POSTGRES_DATABASE\": \"\", \"POSTGRES_USER\": \"\", \"POSTGRES_PASSWORD\": \"\" } } } } Open Windsurf and navigate to the Cascade assistant.\nTap on the hammer (MCP) icon, then Configure to open the configuration file.\nAdd the following configuration, replace the environment variables with your values, and save:\n{ \"mcpServers\": { \"postgres\": { \"command\": \"./PATH/TO/toolbox\", \"args\": [\"--prebuilt\",\"postgres\",\"--stdio\"], \"env\": { \"POSTGRES_HOST\": \"\", \"POSTGRES_PORT\": \"\", \"POSTGRES_DATABASE\": \"\", \"POSTGRES_USER\": \"\", \"POSTGRES_PASSWORD\": \"\" } } } } Use Tools Your AI tool is now connected to Postgres using MCP. Try asking your AI assistant to list tables, create a table, or define and execute other SQL statements.\nThe following tools are available to the LLM:\nlist_tables: lists tables and descriptions execute_sql: execute any SQL statement Note\nPrebuilt tools are pre-1.0, so expect some tool changes between versions. LLMs will adapt to the tools available, so this shouldn’t affect most users.\n","categories":"","description":"Connect your IDE to PostgreSQL using Toolbox.\n","excerpt":"Connect your IDE to PostgreSQL using Toolbox.\n","ref":"/genai-toolbox/how-to/connect-ide/postgres_mcp/","tags":"","title":"PostgreSQL using MCP"},{"body":"","categories":"","description":"Python client SDK","excerpt":"Python client SDK","ref":"/genai-toolbox/sdks/python-sdk/","tags":"","title":"Python SDK"},{"body":"\nBefore you begin This guide assumes you have already done the following:\nInstalled Python 3.9+ (including pip and your preferred virtual environment tool for managing dependencies e.g. venv) Installed PostgreSQL 16+ and the psql client Step 1: Set up your database In this section, we will create a database, insert some data that needs to be accessed by our agent, and create a database user for Toolbox to connect with.\nConnect to postgres using the psql command:\npsql -h 127.0.0.1 -U postgres Here, postgres denotes the default postgres superuser.\nInfo\nHaving trouble connecting? Password Prompt: If you are prompted for a password for the postgres user and do not know it (or a blank password doesn’t work), your PostgreSQL installation might require a password or a different authentication method. FATAL: role \"postgres\" does not exist: This error means the default postgres superuser role isn’t available under that name on your system. Connection refused: Ensure your PostgreSQL server is actually running. You can typically check with sudo systemctl status postgresql and start it with sudo systemctl start postgresql on Linux systems. Common Solution For password issues or if the postgres role seems inaccessible directly, try switching to the postgres operating system user first. This user often has permission to connect without a password for local connections (this is called peer authentication).\nsudo -i -u postgres psql -h 127.0.0.1 Once you are in the psql shell using this method, you can proceed with the database creation steps below. Afterwards, type \\q to exit psql, and then exit to return to your normal user shell.\nIf desired, once connected to psql as the postgres OS user, you can set a password for the postgres database user using: ALTER USER postgres WITH PASSWORD 'your_chosen_password';. This would allow direct connection with -U postgres and a password next time.\nCreate a new database and a new user:\nTip\nFor a real application, it’s best to follow the principle of least permission and only grant the privileges your application needs.\nCREATE USER toolbox_user WITH PASSWORD 'my-password'; CREATE DATABASE toolbox_db; GRANT ALL PRIVILEGES ON DATABASE toolbox_db TO toolbox_user; ALTER DATABASE toolbox_db OWNER TO toolbox_user; End the database session:\n\\q (If you used sudo -i -u postgres and then psql, remember you might also need to type exit after \\q to leave the postgres user’s shell session.)\nConnect to your database with your new user:\npsql -h 127.0.0.1 -U toolbox_user -d toolbox_db Create a table using the following command:\nCREATE TABLE hotels( id INTEGER NOT NULL PRIMARY KEY, name VARCHAR NOT NULL, location VARCHAR NOT NULL, price_tier VARCHAR NOT NULL, checkin_date DATE NOT NULL, checkout_date DATE NOT NULL, booked BIT NOT NULL ); Insert data into the table.\nINSERT INTO hotels(id, name, location, price_tier, checkin_date, checkout_date, booked) VALUES (1, 'Hilton Basel', 'Basel', 'Luxury', '2024-04-22', '2024-04-20', B'0'), (2, 'Marriott Zurich', 'Zurich', 'Upscale', '2024-04-14', '2024-04-21', B'0'), (3, 'Hyatt Regency Basel', 'Basel', 'Upper Upscale', '2024-04-02', '2024-04-20', B'0'), (4, 'Radisson Blu Lucerne', 'Lucerne', 'Midscale', '2024-04-24', '2024-04-05', B'0'), (5, 'Best Western Bern', 'Bern', 'Upper Midscale', '2024-04-23', '2024-04-01', B'0'), (6, 'InterContinental Geneva', 'Geneva', 'Luxury', '2024-04-23', '2024-04-28', B'0'), (7, 'Sheraton Zurich', 'Zurich', 'Upper Upscale', '2024-04-27', '2024-04-02', B'0'), (8, 'Holiday Inn Basel', 'Basel', 'Upper Midscale', '2024-04-24', '2024-04-09', B'0'), (9, 'Courtyard Zurich', 'Zurich', 'Upscale', '2024-04-03', '2024-04-13', B'0'), (10, 'Comfort Inn Bern', 'Bern', 'Midscale', '2024-04-04', '2024-04-16', B'0'); End the database session:\n\\q Step 2: Install and configure Toolbox In this section, we will download Toolbox, configure our tools in a tools.yaml, and then run the Toolbox server.\nDownload the latest version of Toolbox as a binary:\nTip\nSelect the correct binary corresponding to your OS and CPU architecture.\nexport OS=\"linux/amd64\" # one of linux/amd64, darwin/arm64, darwin/amd64, or windows/amd64 curl -O https://storage.googleapis.com/genai-toolbox/v0.8.0/$OS/toolbox Make the binary executable:\nchmod +x toolbox Write the following into a tools.yaml file. Be sure to update any fields such as user, password, or database that you may have customized in the previous step.\nTip\nIn practice, use environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nsources: my-pg-source: kind: postgres host: 127.0.0.1 port: 5432 database: toolbox_db user: ${USER_NAME} password: ${PASSWORD} tools: search-hotels-by-name: kind: postgres-sql source: my-pg-source description: Search for hotels based on name. parameters: - name: name type: string description: The name of the hotel. statement: SELECT * FROM hotels WHERE name ILIKE '%' || $1 || '%'; search-hotels-by-location: kind: postgres-sql source: my-pg-source description: Search for hotels based on location. parameters: - name: location type: string description: The location of the hotel. statement: SELECT * FROM hotels WHERE location ILIKE '%' || $1 || '%'; book-hotel: kind: postgres-sql source: my-pg-source description: \u003e- Book a hotel by its ID. If the hotel is successfully booked, returns a NULL, raises an error if not. parameters: - name: hotel_id type: string description: The ID of the hotel to book. statement: UPDATE hotels SET booked = B'1' WHERE id = $1; update-hotel: kind: postgres-sql source: my-pg-source description: \u003e- Update a hotel's check-in and check-out dates by its ID. Returns a message indicating whether the hotel was successfully updated or not. parameters: - name: hotel_id type: string description: The ID of the hotel to update. - name: checkin_date type: string description: The new check-in date of the hotel. - name: checkout_date type: string description: The new check-out date of the hotel. statement: \u003e- UPDATE hotels SET checkin_date = CAST($2 as date), checkout_date = CAST($3 as date) WHERE id = $1; cancel-hotel: kind: postgres-sql source: my-pg-source description: Cancel a hotel by its ID. parameters: - name: hotel_id type: string description: The ID of the hotel to cancel. statement: UPDATE hotels SET booked = B'0' WHERE id = $1; toolsets: my-toolset: - search-hotels-by-name - search-hotels-by-location - book-hotel - update-hotel - cancel-hotel For more info on tools, check out the Resources section of the docs.\nRun the Toolbox server, pointing to the tools.yaml file created earlier:\n./toolbox --tools-file \"tools.yaml\" Note\nToolbox enables dynamic reloading by default. To disable, use the `--disable-reload` flag. Step 3: Connect your agent to Toolbox In this section, we will write and run an agent that will load the Tools from Toolbox.\nTip\nIf you prefer to experiment within a Google Colab environment, you can connect to a local runtime.\nIn a new terminal, install the SDK package.\nADK Langchain LlamaIndex Core pip install toolbox-core pip install toolbox-langchain pip install toolbox-llamaindex pip install toolbox-core Install other required dependencies:\nADK Langchain LlamaIndex Core pip install google-adk # TODO(developer): replace with correct package if needed pip install langgraph langchain-google-vertexai # pip install langchain-google-genai # pip install langchain-anthropic # TODO(developer): replace with correct package if needed pip install llama-index-llms-google-genai # pip install llama-index-llms-anthropic pip install google-genai Create a new file named hotel_agent.py and copy the following code to create an agent: ADK LangChain LlamaIndex Core from google.adk.agents import Agent from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.adk.artifacts.in_memory_artifact_service import InMemoryArtifactService from google.genai import types from toolbox_core import ToolboxSyncClient import asyncio import os # TODO(developer): replace this with your Google API key os.environ['GOOGLE_API_KEY'] = 'your-api-key' async def main(): with ToolboxSyncClient(\"\u003chttp://127.0.0.1:5000\u003e\") as toolbox_client: prompt = \"\"\" You're a helpful hotel assistant. You handle hotel searching, booking and cancellations. When the user searches for a hotel, mention it's name, id, location and price tier. Always mention hotel ids while performing any searches. This is very important for any operations. For any bookings or cancellations, please provide the appropriate confirmation. Be sure to update checkin or checkout dates if mentioned by the user. Don't ask for confirmations from the user. \"\"\" root_agent = Agent( model='gemini-2.0-flash-001', name='hotel_agent', description='A helpful AI assistant.', instruction=prompt, tools=toolbox_client.load_toolset(\"my-toolset\"), ) session_service = InMemorySessionService() artifacts_service = InMemoryArtifactService() session = await session_service.create_session( state={}, app_name='hotel_agent', user_id='123' ) runner = Runner( app_name='hotel_agent', agent=root_agent, artifact_service=artifacts_service, session_service=session_service, ) queries = [ \"Find hotels in Basel with Basel in it's name.\", \"Can you book the Hilton Basel for me?\", \"Oh wait, this is too expensive. Please cancel it and book the Hyatt Regency instead.\", \"My check in dates would be from April 10, 2024 to April 19, 2024.\", ] for query in queries: content = types.Content(role='user', parts=[types.Part(text=query)]) events = runner.run(session_id=session.id, user_id='123', new_message=content) responses = ( part.text for event in events for part in event.content.parts if part.text is not None ) for text in responses: print(text) asyncio.run(main()) import asyncio from langgraph.prebuilt import create_react_agent # TODO(developer): replace this with another import if needed from langchain_google_vertexai import ChatVertexAI # from langchain_google_genai import ChatGoogleGenerativeAI # from langchain_anthropic import ChatAnthropic from langgraph.checkpoint.memory import MemorySaver from toolbox_langchain import ToolboxClient prompt = \"\"\" You're a helpful hotel assistant. You handle hotel searching, booking and cancellations. When the user searches for a hotel, mention it's name, id, location and price tier. Always mention hotel ids while performing any searches. This is very important for any operations. For any bookings or cancellations, please provide the appropriate confirmation. Be sure to update checkin or checkout dates if mentioned by the user. Don't ask for confirmations from the user. \"\"\" queries = [ \"Find hotels in Basel with Basel in it's name.\", \"Can you book the Hilton Basel for me?\", \"Oh wait, this is too expensive. Please cancel it and book the Hyatt Regency instead.\", \"My check in dates would be from April 10, 2024 to April 19, 2024.\", ] async def run_application(): # TODO(developer): replace this with another model if needed model = ChatVertexAI(model_name=\"gemini-2.0-flash-001\") # model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\") # model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\") # Load the tools from the Toolbox server async with ToolboxClient(\"http://127.0.0.1:5000\") as client: tools = await client.aload_toolset() agent = create_react_agent(model, tools, checkpointer=MemorySaver()) config = {\"configurable\": {\"thread_id\": \"thread-1\"}} for query in queries: inputs = {\"messages\": [(\"user\", prompt + query)]} response = agent.invoke(inputs, stream_mode=\"values\", config=config) print(response[\"messages\"][-1].content) asyncio.run(run_application()) import asyncio import os from llama_index.core.agent.workflow import AgentWorkflow from llama_index.core.workflow import Context # TODO(developer): replace this with another import if needed from llama_index.llms.google_genai import GoogleGenAI # from llama_index.llms.anthropic import Anthropic from toolbox_llamaindex import ToolboxClient prompt = \"\"\" You're a helpful hotel assistant. You handle hotel searching, booking and cancellations. When the user searches for a hotel, mention it's name, id, location and price tier. Always mention hotel ids while performing any searches. This is very important for any operations. For any bookings or cancellations, please provide the appropriate confirmation. Be sure to update checkin or checkout dates if mentioned by the user. Don't ask for confirmations from the user. \"\"\" queries = [ \"Find hotels in Basel with Basel in it's name.\", \"Can you book the Hilton Basel for me?\", \"Oh wait, this is too expensive. Please cancel it and book the Hyatt Regency instead.\", \"My check in dates would be from April 10, 2024 to April 19, 2024.\", ] async def run_application(): # TODO(developer): replace this with another model if needed llm = GoogleGenAI( model=\"gemini-2.0-flash-001\", vertexai_config={\"project\": \"project-id\", \"location\": \"us-central1\"}, ) # llm = GoogleGenAI( # api_key=os.getenv(\"GOOGLE_API_KEY\"), # model=\"gemini-2.0-flash-001\", # ) # llm = Anthropic( # model=\"claude-3-7-sonnet-latest\", # api_key=os.getenv(\"ANTHROPIC_API_KEY\") # ) # Load the tools from the Toolbox server async with ToolboxClient(\"http://127.0.0.1:5000\") as client: tools = await client.aload_toolset() agent = AgentWorkflow.from_tools_or_functions( tools, llm=llm, system_prompt=prompt, ) ctx = Context(agent) for query in queries: response = await agent.run(user_msg=query, ctx=ctx) print(f\"---- {query} ----\") print(str(response)) asyncio.run(run_application()) import asyncio from google import genai from google.genai.types import ( Content, FunctionDeclaration, GenerateContentConfig, Part, Tool, ) from toolbox_core import ToolboxClient prompt = \"\"\" You're a helpful hotel assistant. You handle hotel searching, booking and cancellations. When the user searches for a hotel, mention it's name, id, location and price tier. Always mention hotel id while performing any searches. This is very important for any operations. For any bookings or cancellations, please provide the appropriate confirmation. Be sure to update checkin or checkout dates if mentioned by the user. Don't ask for confirmations from the user. \"\"\" queries = [ \"Find hotels in Basel with Basel in it's name.\", \"Please book the hotel Hilton Basel for me.\", \"This is too expensive. Please cancel it.\", \"Please book Hyatt Regency for me\", \"My check in dates for my booking would be from April 10, 2024 to April 19, 2024.\", ] async def run_application(): async with ToolboxClient(\"\u003chttp://127.0.0.1:5000\u003e\") as toolbox_client: # The toolbox_tools list contains Python callables (functions/methods) designed for LLM tool-use # integration. While this example uses Google's genai client, these callables can be adapted for # various function-calling or agent frameworks. For easier integration with supported frameworks # (https://github.com/googleapis/mcp-toolbox-python-sdk/tree/main/packages), use the # provided wrapper packages, which handle framework-specific boilerplate. toolbox_tools = await toolbox_client.load_toolset(\"my-toolset\") genai_client = genai.Client( vertexai=True, project=\"project-id\", location=\"us-central1\" ) genai_tools = [ Tool( function_declarations=[ FunctionDeclaration.from_callable_with_api_option(callable=tool) ] ) for tool in toolbox_tools ] history = [] for query in queries: user_prompt_content = Content( role=\"user\", parts=[Part.from_text(text=query)], ) history.append(user_prompt_content) response = genai_client.models.generate_content( model=\"gemini-2.0-flash-001\", contents=history, config=GenerateContentConfig( system_instruction=prompt, tools=genai_tools, ), ) history.append(response.candidates[0].content) function_response_parts = [] for function_call in response.function_calls: fn_name = function_call.name # The tools are sorted alphabetically if fn_name == \"search-hotels-by-name\": function_result = await toolbox_tools[3](**function_call.args) elif fn_name == \"search-hotels-by-location\": function_result = await toolbox_tools[2](**function_call.args) elif fn_name == \"book-hotel\": function_result = await toolbox_tools[0](**function_call.args) elif fn_name == \"update-hotel\": function_result = await toolbox_tools[4](**function_call.args) elif fn_name == \"cancel-hotel\": function_result = await toolbox_tools[1](**function_call.args) else: raise ValueError(\"Function name not present.\") function_response = {\"result\": function_result} function_response_part = Part.from_function_response( name=function_call.name, response=function_response, ) function_response_parts.append(function_response_part) if function_response_parts: tool_response_content = Content(role=\"tool\", parts=function_response_parts) history.append(tool_response_content) response2 = genai_client.models.generate_content( model=\"gemini-2.0-flash-001\", contents=history, config=GenerateContentConfig( tools=genai_tools, ), ) final_model_response_content = response2.candidates[0].content history.append(final_model_response_content) print(response2.text) asyncio.run(run_application()) ADK Langchain LlamaIndex Core To learn more about Agent Development Kit, check out the ADK documentation.\nTo learn more about Agents in LangChain, check out the LangGraph Agent documentation.\nTo learn more about Agents in LlamaIndex, check out the LlamaIndex AgentWorkflow documentation.\nTo learn more about tool calling with Google GenAI, check out the Google GenAI Documentation.\nRun your agent, and observe the results:\npython hotel_agent.py ","categories":"","description":"How to get started running Toolbox locally with Python, PostgreSQL, and  [Agent Development Kit](https://google.github.io/adk-docs/), [LangGraph](https://www.langchain.com/langgraph), [LlamaIndex](https://www.llamaindex.ai/) or [GoogleGenAI](https://pypi.org/project/google-genai/).\n","excerpt":"How to get started running Toolbox locally with Python, PostgreSQL, …","ref":"/genai-toolbox/getting-started/local_quickstart/","tags":"","title":"Quickstart (Local)"},{"body":"Overview Model Context Protocol is an open protocol that standardizes how applications provide context to LLMs. Check out this page on how to connect to Toolbox via MCP.\nStep 1: Set up your BigQuery Dataset and Table In this section, we will create a BigQuery dataset and a table, then insert some data that needs to be accessed by our agent.\nCreate a new BigQuery dataset (replace YOUR_DATASET_NAME with your desired dataset name, e.g., toolbox_mcp_ds, and optionally specify a location like US or EU):\nexport BQ_DATASET_NAME=\"YOUR_DATASET_NAME\" export BQ_LOCATION=\"US\" bq --location=$BQ_LOCATION mk $BQ_DATASET_NAME You can also do this through the Google Cloud Console.\nThe hotels table needs to be defined in your new dataset. First, create a file named create_hotels_table.sql with the following content:\nCREATE TABLE IF NOT EXISTS `YOUR_PROJECT_ID.YOUR_DATASET_NAME.hotels` ( id INT64 NOT NULL, name STRING NOT NULL, location STRING NOT NULL, price_tier STRING NOT NULL, checkin_date DATE NOT NULL, checkout_date DATE NOT NULL, booked BOOLEAN NOT NULL ); Note: Replace YOUR_PROJECT_ID and YOUR_DATASET_NAME in the SQL with your actual project ID and dataset name.\nThen run the command below to execute the sql query:\nbq query --project_id=$GOOGLE_CLOUD_PROJECT --dataset_id=$BQ_DATASET_NAME --use_legacy_sql=false \u003c create_hotels_table.sql . Next, populate the hotels table with some initial data. To do this, create a file named insert_hotels_data.sql and add the following SQL INSERT statement to it.\nINSERT INTO `YOUR_PROJECT_ID.YOUR_DATASET_NAME.hotels` (id, name, location, price_tier, checkin_date, checkout_date, booked) VALUES (1, 'Hilton Basel', 'Basel', 'Luxury', '2024-04-20', '2024-04-22', FALSE), (2, 'Marriott Zurich', 'Zurich', 'Upscale', '2024-04-14', '2024-04-21', FALSE), (3, 'Hyatt Regency Basel', 'Basel', 'Upper Upscale', '2024-04-02', '2024-04-20', FALSE), (4, 'Radisson Blu Lucerne', 'Lucerne', 'Midscale', '2024-04-05', '2024-04-24', FALSE), (5, 'Best Western Bern', 'Bern', 'Upper Midscale', '2024-04-01', '2024-04-23', FALSE), (6, 'InterContinental Geneva', 'Geneva', 'Luxury', '2024-04-23', '2024-04-28', FALSE), (7, 'Sheraton Zurich', 'Zurich', 'Upper Upscale', '2024-04-02', '2024-04-27', FALSE), (8, 'Holiday Inn Basel', 'Basel', 'Upper Midscale', '2024-04-09', '2024-04-24', FALSE), (9, 'Courtyard Zurich', 'Zurich', 'Upscale', '2024-04-03', '2024-04-13', FALSE), (10, 'Comfort Inn Bern', 'Bern', 'Midscale', '2024-04-04', '2024-04-16', FALSE); Note: Replace YOUR_PROJECT_ID and YOUR_DATASET_NAME in the SQL with your actual project ID and dataset name.\nThen run the command below to execute the sql query:\nbq query --project_id=$GOOGLE_CLOUD_PROJECT --dataset_id=$BQ_DATASET_NAME --use_legacy_sql=false \u003c insert_hotels_data.sql Step 2: Install and configure Toolbox In this section, we will download Toolbox, configure our tools in a tools.yaml, and then run the Toolbox server.\nDownload the latest version of Toolbox as a binary:\nTip\nSelect the correct binary corresponding to your OS and CPU architecture.\nexport OS=\"linux/amd64\" # one of linux/amd64, darwin/arm64, darwin/amd64, or windows/amd64 curl -O https://storage.googleapis.com/genai-toolbox/v0.8.0/$OS/toolbox Make the binary executable:\nchmod +x toolbox Write the following into a tools.yaml file. You must replace the YOUR_PROJECT_ID and YOUR_DATASET_NAME placeholder in the config with your actual BigQuery project and dataset name. The location field is optional; if not specified, it defaults to ‘us’. The table name hotels is used directly in the statements.\nTip\nAuthentication with BigQuery is handled via Application Default Credentials (ADC). Ensure you have run gcloud auth application-default login.\nsources: my-bigquery-source: kind: bigquery project: YOUR_PROJECT_ID location: us tools: search-hotels-by-name: kind: bigquery-sql source: my-bigquery-source description: Search for hotels based on name. parameters: - name: name type: string description: The name of the hotel. statement: SELECT * FROM `YOUR_DATASET_NAME.hotels` WHERE LOWER(name) LIKE LOWER(CONCAT('%', @name, '%')); search-hotels-by-location: kind: bigquery-sql source: my-bigquery-source description: Search for hotels based on location. parameters: - name: location type: string description: The location of the hotel. statement: SELECT * FROM `YOUR_DATASET_NAME.hotels` WHERE LOWER(location) LIKE LOWER(CONCAT('%', @location, '%')); book-hotel: kind: bigquery-sql source: my-bigquery-source description: \u003e- Book a hotel by its ID. If the hotel is successfully booked, returns a NULL, raises an error if not. parameters: - name: hotel_id type: integer description: The ID of the hotel to book. statement: UPDATE `YOUR_DATASET_NAME.hotels` SET booked = TRUE WHERE id = @hotel_id; update-hotel: kind: bigquery-sql source: my-bigquery-source description: \u003e- Update a hotel's check-in and check-out dates by its ID. Returns a message indicating whether the hotel was successfully updated or not. parameters: - name: checkin_date type: string description: The new check-in date of the hotel. - name: checkout_date type: string description: The new check-out date of the hotel. - name: hotel_id type: integer description: The ID of the hotel to update. statement: \u003e- UPDATE `YOUR_DATASET_NAME.hotels` SET checkin_date = PARSE_DATE('%Y-%m-%d', @checkin_date), checkout_date = PARSE_DATE('%Y-%m-%d', @checkout_date) WHERE id = @hotel_id; cancel-hotel: kind: bigquery-sql source: my-bigquery-source description: Cancel a hotel by its ID. parameters: - name: hotel_id type: integer description: The ID of the hotel to cancel. statement: UPDATE `YOUR_DATASET_NAME.hotels` SET booked = FALSE WHERE id = @hotel_id; toolsets: my-toolset: - search-hotels-by-name - search-hotels-by-location - book-hotel - update-hotel - cancel-hotel For more info on tools, check out the Tools section.\nRun the Toolbox server, pointing to the tools.yaml file created earlier:\n./toolbox --tools-file \"tools.yaml\" Step 3: Connect to MCP Inspector Run the MCP Inspector:\nnpx @modelcontextprotocol/inspector Type y when it asks to install the inspector package.\nIt should show the following when the MCP Inspector is up and running:\n🔍 MCP Inspector is up and running at http://127.0.0.1:5173 🚀 Open the above link in your browser.\nFor Transport Type, select SSE.\nFor URL, type in http://127.0.0.1:5000/mcp/sse.\nClick Connect.\nSelect List Tools, you will see a list of tools configured in tools.yaml.\nTest out your tools here!\n","categories":"","description":"How to get started running Toolbox with MCP Inspector and BigQuery as the source.\n","excerpt":"How to get started running Toolbox with MCP Inspector and BigQuery as …","ref":"/genai-toolbox/samples/bigquery/mcp_quickstart/","tags":"","title":"Quickstart (MCP with BigQuery)"},{"body":" ","categories":"","description":"Connect your IDE to Spanner using Toolbox.\n","excerpt":"Connect your IDE to Spanner using Toolbox.\n","ref":"/genai-toolbox/how-to/connect-ide/spanner_mcp/","tags":"","title":"Spanner using MCP"},{"body":"About Telemetry data such as logs, metrics, and traces will help developers understand the internal state of the system. This page walks though different types of telemetry and observability available in Toolbox.\nToolbox exports telemetry data of logs via standard out/err, and traces/metrics through OpenTelemetry. Additional flags can be passed to Toolbox to enable different logging behavior, or to export metrics through a specific exporter.\nLogging The following flags can be used to customize Toolbox logging:\nFlag Description --log-level Preferred log level, allowed values: debug, info, warn, error. Default: info. --logging-format Preferred logging format, allowed values: standard, json. Default: standard. Example:\n./toolbox --tools-file \"tools.yaml\" --log-level warn --logging-format json Level Toolbox supports the following log levels, including:\nLog level Description Debug Debug logs typically contain information that is only useful during the debugging phase and may be of little value during production. Info Info logs include information about successful operations within the application, such as a successful start, pause, or exit of the application. Warn Warning logs are slightly less severe than error conditions. While it does not cause an error, it indicates that an operation might fail in the future if action is not taken now. Error Error log is assigned to event logs that contain an application error message. Toolbox will only output logs that are equal or more severe to the level that it is set. Below are the log levels that Toolbox supports in the order of severity.\nFormat Toolbox supports both standard and structured logging format.\nThe standard logging outputs log as string:\n2024-11-12T15:08:11.451377-08:00 INFO \"Initialized 0 sources.\\n\" The structured logging outputs log as JSON:\n{ \"timestamp\":\"2024-11-04T16:45:11.987299-08:00\", \"severity\":\"ERROR\", \"logging.googleapis.com/sourceLocation\":{...}, \"message\":\"unable to parse tool file at \\\"tools.yaml\\\": \\\"cloud-sql-postgres1\\\" is not a valid kind of data source\" } Tip\nlogging.googleapis.com/sourceLocation shows the source code location information associated with the log entry, if any.\nTelemetry Toolbox is supports exporting metrics and traces to any OpenTelemetry compatible exporter.\nMetrics A metric is a measurement of a service captured at runtime. The collected data can be used to provide important insights into the service. Toolbox provides the following custom metrics:\nMetric Name Description toolbox.server.toolset.get.count Counts the number of toolset manifest requests served toolbox.server.tool.get.count Counts the number of tool manifest requests served toolbox.server.tool.get.invoke Counts the number of tool invocation requests served toolbox.server.mcp.sse.count Counts the number of mcp sse connection requests served toolbox.server.mcp.post.count Counts the number of mcp post requests served All custom metrics have the following attributes/labels:\nMetric Attributes Description toolbox.name Name of the toolset or tool, if applicable. toolbox.operation.status Operation status code, for example: success, failure. toolbox.sse.sessionId Session id for sse connection, if applicable. toolbox.method Method of JSON-RPC request, if applicable. Traces A trace is a tree of spans that shows the path that a request makes through an application.\nSpans generated by Toolbox server is prefixed with toolbox/server/. For example, when user run Toolbox, it will generate spans for the following, with toolbox/server/init as the root span:\nResource Attributes All metrics and traces generated within Toolbox will be associated with a unified resource. The list of resource attributes included are:\nResource Name Description TelemetrySDK TelemetrySDK version info. OS OS attributes including OS description and OS type. Container Container attributes including container ID, if applicable. Host Host attributes including host name. SchemaURL Sets the schema URL for the configured resource. service.name Open telemetry service name. Defaulted to toolbox. User can set the service name via flag mentioned above to distinguish between different toolbox service. service.version The version of Toolbox used. Exporter An exporter is responsible for processing and exporting telemetry data. Toolbox generates telemetry data within the OpenTelemetry Protocol (OTLP), and user can choose to use exporters that are designed to support the OpenTelemetry Protocol. Within Toolbox, we provide two types of exporter implementation to choose from, either the Google Cloud Exporter that will send data directly to the backend, or the OTLP Exporter along with a Collector that will act as a proxy to collect and export data to the telemetry backend of user’s choice.\nGoogle Cloud Exporter The Google Cloud Exporter directly exports telemetry to Google Cloud Monitoring. It utilizes the GCP Metric Exporter and GCP Trace Exporter.\nNote\nIf you’re using Google Cloud Monitoring, the following APIs will need to be enabled:\nCloud Logging API Cloud Monitoring API Cloud Trace API OTLP Exporter This implementation uses the default OTLP Exporter over HTTP for metrics and traces. You can use this exporter if you choose to export your telemetry data to a Collector.\nCollector A collector acts as a proxy between the application and the telemetry backend. It receives telemetry data, transforms it, and then exports data to backends that can store it permanently. Toolbox provide an option to export telemetry data to user’s choice of backend(s) that are compatible with the Open Telemetry Protocol (OTLP). If you would like to use a collector, please refer to this Export Telemetry using the Otel Collector.\nFlags The following flags are used to determine Toolbox’s telemetry configuration:\nflag type description --telemetry-gcp bool Enable exporting directly to Google Cloud Monitoring. Default is false. --telemetry-otlp string Enable exporting using OpenTelemetry Protocol (OTLP) to the specified endpoint (e.g. “http://127.0.0.1:4318”). --telemetry-service-name string Sets the value of the service.name resource attribute. Default is toolbox. In addition to the flags noted above, you can also make additional configuration for OpenTelemetry via the General SDK Configuration through environmental variables.\nExamples:\nTo enable Google Cloud Exporter:\n./toolbox --telemetry-gcp To enable OTLP Exporter, provide Collector endpoint:\n./toolbox --telemetry-otlp=\"http://127.0.0.1:4553\" ","categories":"","description":"An overview of telemetry and observability in Toolbox. \n","excerpt":"An overview of telemetry and observability in Toolbox. \n","ref":"/genai-toolbox/concepts/telemetry/","tags":"","title":"Telemetry"},{"body":"A tool represents an action your agent can take, such as running a SQL statement. You can define Tools as a map in the tools section of your tools.yaml file. Typically, a tool will require a source to act on:\ntools: search_flights_by_number: kind: postgres-sql source: my-pg-instance statement: | SELECT * FROM flights WHERE airline = $1 AND flight_number = $2 LIMIT 10 description: | Use this tool to get information for a specific flight. Takes an airline code and flight number and returns info on the flight. Do NOT use this tool with a flight id. Do NOT guess an airline code or flight number. An airline code is a code for an airline service consisting of a two-character airline designator and followed by a flight number, which is a 1 to 4 digit number. For example, if given CY 0123, the airline is \"CY\", and flight_number is \"123\". Another example for this is DL 1234, the airline is \"DL\", and flight_number is \"1234\". If the tool returns more than one option choose the date closest to today. Example: {{ \"airline\": \"CY\", \"flight_number\": \"888\", }} Example: {{ \"airline\": \"DL\", \"flight_number\": \"1234\", }} parameters: - name: airline type: string description: Airline unique 2 letter identifier - name: flight_number type: string description: 1 to 4 digit number Specifying Parameters Parameters for each Tool will define what inputs the agent will need to provide to invoke them. Parameters should be pass as a list of Parameter objects:\nparameters: - name: airline type: string description: Airline unique 2 letter identifier - name: flight_number type: string description: 1 to 4 digit number Basic Parameters Basic parameters types include string, integer, float, boolean types. In most cases, the description will be provided to the LLM as context on specifying the parameter.\nparameters: - name: airline type: string description: Airline unique 2 letter identifier field type required description name string true Name of the parameter. type string true Must be one of “string”, “integer”, “float”, “boolean” “array” default parameter type false Default value of the parameter. If provided, the parameter is not required. description string true Natural language description of the parameter to describe it to the agent. Array Parameters The array type is a list of items passed in as a single parameter. To use the array type, you must also specify what kind of items are in the list using the items field:\nparameters: - name: preferred_airlines type: array description: A list of airline, ordered by preference. items: name: name type: string description: Name of the airline. statement: | SELECT * FROM airlines WHERE preferred_airlines = ANY($1); field type required description name string true Name of the parameter. type string true Must be “array” default parameter type false Default value of the parameter. If provided, the parameter is not required. description string true Natural language description of the parameter to describe it to the agent. items parameter object true Specify a Parameter object for the type of the values in the array. Note\nItems in array should not have a default value. If provided, it will be ignored.\nAuthenticated Parameters Authenticated parameters are automatically populated with user information decoded from ID tokens that are passed in request headers. They do not take input values in request bodies like other parameters. To use authenticated parameters, you must configure the tool to map the required authServices to specific claims within the user’s ID token.\ntools: search_flights_by_user_id: kind: postgres-sql source: my-pg-instance statement: | SELECT * FROM flights WHERE user_id = $1 parameters: - name: user_id type: string description: Auto-populated from Google login authServices: # Refer to one of the `authServices` defined - name: my-google-auth # `sub` is the OIDC claim field for user ID field: sub field type required description name string true Name of the authServices used to verify the OIDC auth token. field string true Claim field decoded from the OIDC token used to auto-populate this parameter. Template Parameters Template parameters types include string, integer, float, boolean types. In most cases, the description will be provided to the LLM as context on specifying the parameter. Template parameters will be inserted into the SQL statement before executing the prepared statement. They will be inserted without quotes, so to insert a string using template parameters, quotes must be explicitly added within the string.\nTemplate parameter arrays can also be used similarly to basic parameters, and array items must be strings. Once inserted into the SQL statement, the outer layer of quotes will be removed. Therefore to insert strings into the SQL statement, a set of quotes must be explicitly added within the string.\nWarning\nBecause template parameters can directly replace identifiers, column names, and table names, they are prone to SQL injections. Basic parameters are preferred for performance and safety reasons.\ntools: select_columns_from_table: kind: postgres-sql source: my-pg-instance statement: | SELECT {{array .columnNames}} FROM {{.tableName}} description: | Use this tool to list all information from a specific table. Example: {{ \"tableName\": \"flights\", \"columnNames\": [\"id\", \"name\"] }} templateParameters: - name: tableName type: string description: Table to select from - name: columnNames type: array description: The columns to select items: name: column type: string description: Name of a column to select field type required description name string true Name of the template parameter. type string true Must be one of “string”, “integer”, “float”, “boolean” “array” description string true Natural language description of the template parameter to describe it to the agent. items parameter object true (if array) Specify a Parameter object for the type of the values in the array (string only). Authorized Invocations You can require an authorization check for any Tool invocation request by specifying an authRequired field. Specify a list of authServices defined in the previous section.\ntools: search_all_flight: kind: postgres-sql source: my-pg-instance statement: | SELECT * FROM flights # A list of `authServices` defined previously authRequired: - my-google-auth - other-auth-service Kinds of tools ","categories":"","description":"Tools define actions an agent can take -- such as reading and writing to a  source.\n","excerpt":"Tools define actions an agent can take -- such as reading and writing …","ref":"/genai-toolbox/resources/tools/","tags":"","title":"Tools"},{"body":"Before you begin Install the Google Cloud CLI.\nSet the PROJECT_ID environment variable:\nexport PROJECT_ID=\"my-project-id\" Initialize gcloud CLI:\ngcloud init gcloud config set project $PROJECT_ID Make sure you’ve set up and initialized your database.\nYou must have the following APIs enabled:\ngcloud services enable run.googleapis.com \\ cloudbuild.googleapis.com \\ artifactregistry.googleapis.com \\ iam.googleapis.com \\ secretmanager.googleapis.com To create an IAM account, you must have the following IAM permissions (or roles):\nCreate Service Account role (roles/iam.serviceAccountCreator) To create a secret, you must have the following roles:\nSecret Manager Admin role (roles/secretmanager.admin) To deploy to Cloud Run, you must have the following set of roles:\nCloud Run Developer (roles/run.developer) Service Account User role (roles/iam.serviceAccountUser) Note\nIf you are using sources that require VPC-access (such as AlloyDB or Cloud SQL over private IP), make sure your Cloud Run service and the database are in the same VPC network.\nCreate a service account Create a backend service account if you don’t already have one:\ngcloud iam service-accounts create toolbox-identity Grant permissions to use secret manager:\ngcloud projects add-iam-policy-binding $PROJECT_ID \\ --member serviceAccount:toolbox-identity@$PROJECT_ID.iam.gserviceaccount.com \\ --role roles/secretmanager.secretAccessor Grant additional permissions to the service account that are specific to the source, e.g.:\nAlloyDB for PostgreSQL Cloud SQL for PostgreSQL Configure tools.yaml file Create a tools.yaml file that contains your configuration for Toolbox. For details, see the configuration section.\nDeploy to Cloud Run Upload tools.yaml as a secret:\ngcloud secrets create tools --data-file=tools.yaml If you already have a secret and want to update the secret version, execute the following:\ngcloud secrets versions add tools --data-file=tools.yaml Set an environment variable to the container image that you want to use for cloud run:\nexport IMAGE=us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:latest Deploy Toolbox to Cloud Run using the following command:\ngcloud run deploy toolbox \\ --image $IMAGE \\ --service-account toolbox-identity \\ --region us-central1 \\ --set-secrets \"/app/tools.yaml=tools:latest\" \\ --args=\"--tools-file=/app/tools.yaml\",\"--address=0.0.0.0\",\"--port=8080\" # --allow-unauthenticated # https://cloud.google.com/run/docs/authenticating/public#gcloud If you are using a VPC network, use the command below:\ngcloud run deploy toolbox \\ --image $IMAGE \\ --service-account toolbox-identity \\ --region us-central1 \\ --set-secrets \"/app/tools.yaml=tools:latest\" \\ --args=\"--tools-file=/app/tools.yaml\",\"--address=0.0.0.0\",\"--port=8080\" \\ # TODO(dev): update the following to match your VPC if necessary --network default \\ --subnet default # --allow-unauthenticated # https://cloud.google.com/run/docs/authenticating/public#gcloud Connecting with Toolbox Client SDK You can connect to Toolbox Cloud Run instances directly through the SDK\nSet up Cloud Run Invoker role access to your Cloud Run service.\nSet up Application Default Credentials for the principle you set up the Cloud Run Invoker role access to.\nTip\nIf you’re working in some other environment than local, set up environment specific Default Credentials.\nRun the following to retrieve a non-deterministic URL for the cloud run service:\ngcloud run services describe toolbox --format 'value(status.url)' Import and initialize the toolbox client with the URL retrieved above:\nfrom toolbox_core import ToolboxClient, auth_methods auth_token_provider = auth_methods.aget_google_id_token # can also use sync method # Replace with the Cloud Run service URL generated in the previous step. async with ToolboxClient( URL, client_headers={\"Authorization\": auth_token_provider}, ) as toolbox: Now, you can use this client to connect to the deployed Cloud Run instance!\n","categories":"","description":"How to set up and configure Toolbox to run on Cloud Run.\n","excerpt":"How to set up and configure Toolbox to run on Cloud Run.\n","ref":"/genai-toolbox/how-to/deploy_toolbox/","tags":"","title":"Deploy to Cloud Run"},{"body":"","categories":"","description":"List of guides detailing how to do different things with Toolbox. \n","excerpt":"List of guides detailing how to do different things with Toolbox. \n","ref":"/genai-toolbox/how-to/","tags":"","title":"How-to"},{"body":"Overview Model Context Protocol is an open protocol that standardizes how applications provide context to LLMs. Check out this page on how to connect to Toolbox via MCP.\nStep 1: Set up your database In this section, we will create a database, insert some data that needs to be access by our agent, and create a database user for Toolbox to connect with.\nConnect to postgres using the psql command:\npsql -h 127.0.0.1 -U postgres Here, postgres denotes the default postgres superuser.\nCreate a new database and a new user:\nTip\nFor a real application, it’s best to follow the principle of least permission and only grant the privileges your application needs.\nCREATE USER toolbox_user WITH PASSWORD 'my-password'; CREATE DATABASE toolbox_db; GRANT ALL PRIVILEGES ON DATABASE toolbox_db TO toolbox_user; ALTER DATABASE toolbox_db OWNER TO toolbox_user; End the database session:\n\\q Connect to your database with your new user:\npsql -h 127.0.0.1 -U toolbox_user -d toolbox_db Create a table using the following command:\nCREATE TABLE hotels( id INTEGER NOT NULL PRIMARY KEY, name VARCHAR NOT NULL, location VARCHAR NOT NULL, price_tier VARCHAR NOT NULL, checkin_date DATE NOT NULL, checkout_date DATE NOT NULL, booked BIT NOT NULL ); Insert data into the table.\nINSERT INTO hotels(id, name, location, price_tier, checkin_date, checkout_date, booked) VALUES (1, 'Hilton Basel', 'Basel', 'Luxury', '2024-04-22', '2024-04-20', B'0'), (2, 'Marriott Zurich', 'Zurich', 'Upscale', '2024-04-14', '2024-04-21', B'0'), (3, 'Hyatt Regency Basel', 'Basel', 'Upper Upscale', '2024-04-02', '2024-04-20', B'0'), (4, 'Radisson Blu Lucerne', 'Lucerne', 'Midscale', '2024-04-24', '2024-04-05', B'0'), (5, 'Best Western Bern', 'Bern', 'Upper Midscale', '2024-04-23', '2024-04-01', B'0'), (6, 'InterContinental Geneva', 'Geneva', 'Luxury', '2024-04-23', '2024-04-28', B'0'), (7, 'Sheraton Zurich', 'Zurich', 'Upper Upscale', '2024-04-27', '2024-04-02', B'0'), (8, 'Holiday Inn Basel', 'Basel', 'Upper Midscale', '2024-04-24', '2024-04-09', B'0'), (9, 'Courtyard Zurich', 'Zurich', 'Upscale', '2024-04-03', '2024-04-13', B'0'), (10, 'Comfort Inn Bern', 'Bern', 'Midscale', '2024-04-04', '2024-04-16', B'0'); End the database session:\n\\q Step 2: Install and configure Toolbox In this section, we will download Toolbox, configure our tools in a tools.yaml, and then run the Toolbox server.\nDownload the latest version of Toolbox as a binary:\nTip\nSelect the correct binary corresponding to your OS and CPU architecture.\nexport OS=\"linux/amd64\" # one of linux/amd64, darwin/arm64, darwin/amd64, or windows/amd64 curl -O https://storage.googleapis.com/genai-toolbox/v0.8.0/$OS/toolbox Make the binary executable:\nchmod +x toolbox Write the following into a tools.yaml file. Be sure to update any fields such as user, password, or database that you may have customized in the previous step.\nTip\nIn practice, use environment variable replacement with the format ${ENV_NAME} instead of hardcoding your secrets into the configuration file.\nsources: my-pg-source: kind: postgres host: 127.0.0.1 port: 5432 database: toolbox_db user: toolbox_user password: my-password tools: search-hotels-by-name: kind: postgres-sql source: my-pg-source description: Search for hotels based on name. parameters: - name: name type: string description: The name of the hotel. statement: SELECT * FROM hotels WHERE name ILIKE '%' || $1 || '%'; search-hotels-by-location: kind: postgres-sql source: my-pg-source description: Search for hotels based on location. parameters: - name: location type: string description: The location of the hotel. statement: SELECT * FROM hotels WHERE location ILIKE '%' || $1 || '%'; book-hotel: kind: postgres-sql source: my-pg-source description: \u003e- Book a hotel by its ID. If the hotel is successfully booked, returns a NULL, raises an error if not. parameters: - name: hotel_id type: string description: The ID of the hotel to book. statement: UPDATE hotels SET booked = B'1' WHERE id = $1; update-hotel: kind: postgres-sql source: my-pg-source description: \u003e- Update a hotel's check-in and check-out dates by its ID. Returns a message indicating whether the hotel was successfully updated or not. parameters: - name: hotel_id type: string description: The ID of the hotel to update. - name: checkin_date type: string description: The new check-in date of the hotel. - name: checkout_date type: string description: The new check-out date of the hotel. statement: \u003e- UPDATE hotels SET checkin_date = CAST($2 as date), checkout_date = CAST($3 as date) WHERE id = $1; cancel-hotel: kind: postgres-sql source: my-pg-source description: Cancel a hotel by its ID. parameters: - name: hotel_id type: string description: The ID of the hotel to cancel. statement: UPDATE hotels SET booked = B'0' WHERE id = $1; toolsets: my-toolset: - search-hotels-by-name - search-hotels-by-location - book-hotel - update-hotel - cancel-hotel For more info on tools, check out the Tools section.\nRun the Toolbox server, pointing to the tools.yaml file created earlier:\n./toolbox --tools-file \"tools.yaml\" Step 3: Connect to MCP Inspector Run the MCP Inspector:\nnpx @modelcontextprotocol/inspector Type y when it asks to install the inspector package.\nIt should show the following when the MCP Inspector is up and running:\n🔍 MCP Inspector is up and running at http://127.0.0.1:5173 🚀 Open the above link in your browser.\nFor Transport Type, select SSE.\nFor URL, type in http://127.0.0.1:5000/mcp/sse.\nClick Connect.\nSelect List Tools, you will see a list of tools configured in tools.yaml.\nTest out your tools here!\n","categories":"","description":"How to get started running Toolbox locally with MCP Inspector. \n","excerpt":"How to get started running Toolbox locally with MCP Inspector. \n","ref":"/genai-toolbox/getting-started/mcp_quickstart/","tags":"","title":"Quickstart (MCP)"},{"body":"The primary way to configure Toolbox is through the tools.yaml file. If you have multiple files, you can tell toolbox which to load with the --tools-file tools.yaml flag.\nYou can find more detailed reference documentation to all resource types in the Resources.\nUsing Environment Variables To avoid hardcoding certain secret fields like passwords, usernames, API keys etc., you could use environment variables instead with the format ${ENV_NAME}.\nuser: ${USER_NAME} password: ${PASSWORD} Sources The sources section of your tools.yaml defines what data sources your Toolbox should have access to. Most tools will have at least one source to execute against.\nsources: my-pg-source: kind: postgres host: 127.0.0.1 port: 5432 database: toolbox_db user: ${USER_NAME} password: ${PASSWORD} For more details on configuring different types of sources, see the Sources.\nTools The tools section of your tools.yaml define your the actions your agent can take: what kind of tool it is, which source(s) it affects, what parameters it uses, etc.\ntools: search-hotels-by-name: kind: postgres-sql source: my-pg-source description: Search for hotels based on name. parameters: - name: name type: string description: The name of the hotel. statement: SELECT * FROM hotels WHERE name ILIKE '%' || $1 || '%'; For more details on configuring different types of tools, see the Tools.\nToolsets The toolsets section of your tools.yaml allows you to define groups of tools that you want to be able to load together. This can be useful for defining different sets for different agents or different applications.\ntoolsets: my_first_toolset: - my_first_tool - my_second_tool my_second_toolset: - my_second_tool - my_third_tool You can load toolsets by name:\n# This will load all tools all_tools = client.load_toolset() # This will only load the tools listed in 'my_second_toolset' my_second_toolset = client.load_toolset(\"my_second_toolset\") ","categories":"","description":"How to configure Toolbox's tools.yaml file.\n","excerpt":"How to configure Toolbox's tools.yaml file.\n","ref":"/genai-toolbox/getting-started/configure/","tags":"","title":"Configuration"},{"body":"Before you begin Set the PROJECT_ID environment variable:\nexport PROJECT_ID=\"my-project-id\" Install the gcloud CLI.\nInitialize gcloud CLI:\ngcloud init gcloud config set project $PROJECT_ID You must have the following APIs enabled:\ngcloud services enable artifactregistry.googleapis.com \\ cloudbuild.googleapis.com \\ container.googleapis.com \\ iam.googleapis.com kubectl is used to manage Kubernetes, the cluster orchestration system used by GKE. Verify if you have kubectl installed:\nkubectl version --client If needed, install kubectl component using the Google Cloud CLI:\ngcloud components install kubectl Create a service account Specify a name for your service account with an environment variable:\nexport SA_NAME=toolbox Create a backend service account:\ngcloud iam service-accounts create $SA_NAME Grant any IAM roles necessary to the IAM service account. Each source have a list of necessary IAM permissions listed on it’s page. The example below is for cloud sql postgres source:\ngcloud projects add-iam-policy-binding $PROJECT_ID \\ --member serviceAccount:$SA_NAME@$PROJECT_ID.iam.gserviceaccount.com \\ --role roles/cloudsql.client AlloyDB IAM Identity CloudSQL IAM Identity Spanner IAM Identity Deploy to Kubernetes Set environment variables:\nexport CLUSTER_NAME=toolbox-cluster export DEPLOYMENT_NAME=toolbox export SERVICE_NAME=toolbox-service export REGION=us-central1 export NAMESPACE=toolbox-namespace export SECRET_NAME=toolbox-config export KSA_NAME=toolbox-service-account Create a GKE cluster.\ngcloud container clusters create-auto $CLUSTER_NAME \\ --location=us-central1 Get authentication credentials to interact with the cluster. This also configures kubectl to use the cluster.\ngcloud container clusters get-credentials $CLUSTER_NAME \\ --region=$REGION \\ --project=$PROJECT_ID View the current context for kubectl.\nkubectl config current-context Create namespace for the deployment.\nkubectl create namespace $NAMESPACE Create a Kubernetes Service Account (KSA).\nkubectl create serviceaccount $KSA_NAME --namespace $NAMESPACE Enable the IAM binding between Google Service Account (GSA) and Kubernetes Service Account (KSA).\ngcloud iam service-accounts add-iam-policy-binding \\ --role=\"roles/iam.workloadIdentityUser\" \\ --member=\"serviceAccount:$PROJECT_ID.svc.id.goog[$NAMESPACE/$KSA_NAME]\" \\ $SA_NAME@$PROJECT_ID.iam.gserviceaccount.com Add annotation to KSA to complete binding:\nkubectl annotate serviceaccount \\ $KSA_NAME \\ iam.gke.io/gcp-service-account=$SA_NAME@$PROJECT_ID.iam.gserviceaccount.com \\ --namespace $NAMESPACE Prepare the Kubernetes secret for your tools.yaml file.\nkubectl create secret generic $SECRET_NAME \\ --from-file=./tools.yaml \\ --namespace=$NAMESPACE Create a Kubernetes manifest file (k8s_deployment.yaml) to build deployment.\napiVersion: apps/v1 kind: Deployment metadata: name: toolbox namespace: toolbox-namespace spec: selector: matchLabels: app: toolbox template: metadata: labels: app: toolbox spec: serviceAccountName: toolbox-service-account containers: - name: toolbox # Recommend to use the latest version of toolbox image: us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:latest args: [\"--address\", \"0.0.0.0\"] ports: - containerPort: 5000 volumeMounts: - name: toolbox-config mountPath: \"/app/tools.yaml\" subPath: tools.yaml readOnly: true volumes: - name: toolbox-config secret: secretName: toolbox-config items: - key: tools.yaml path: tools.yaml Create the deployment.\nkubectl apply -f k8s_deployment.yaml --namespace $NAMESPACE Check the status of deployment.\nkubectl get deployments --namespace $NAMESPACE Create a Kubernetes manifest file (k8s_service.yaml) to build service.\napiVersion: v1 kind: Service metadata: name: toolbox-service namespace: toolbox-namespace annotations: cloud.google.com/l4-rbs: \"enabled\" spec: selector: app: toolbox ports: - port: 5000 targetPort: 5000 type: LoadBalancer Create the service.\nkubectl apply -f k8s_service.yaml --namespace $NAMESPACE You can find your IP address created for your service by getting the service information through the following.\nkubectl describe services $SERVICE_NAME --namespace $NAMESPACE To look at logs, run the following.\nkubectl logs -f deploy/$DEPLOYMENT_NAME --namespace $NAMESPACE You might have to wait a couple of minutes. It is ready when you can see EXTERNAL-IP with the following command:\nkubectl get svc -n $NAMESPACE Access toolbox locally.\ncurl \u003cEXTERNAL-IP\u003e:5000 Clean up resources Delete secret.\nkubectl delete secret $SECRET_NAME --namespace $NAMESPACE Delete deployment.\nkubectl delete deployment $DEPLOYMENT_NAME --namespace $NAMESPACE Delete the application’s service.\nkubectl delete service $SERVICE_NAME --namespace $NAMESPACE Delete the Kubernetes cluster.\ngcloud container clusters delete $CLUSTER_NAME \\ --location=$REGION ","categories":"","description":"How to set up and configure Toolbox to deploy on Kubernetes with Google Kubernetes Engine (GKE).\n","excerpt":"How to set up and configure Toolbox to deploy on Kubernetes with …","ref":"/genai-toolbox/how-to/deploy_gke/","tags":"","title":"Deploy to Kubernetes"},{"body":" Before you begin Install Docker Compose. Configure tools.yaml file Create a tools.yaml file that contains your configuration for Toolbox. For details, see the configuration section.\nDeploy using Docker Compose Create a docker-compose.yml file, customizing as needed: services: toolbox: # TODO: It is recommended to pin to a specific image version instead of latest. image: us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:latest hostname: toolbox platform: linux/amd64 ports: - \"5000:5000\" volumes: - ./config:/config command: [ \"toolbox\", \"--tools-file\", \"/config/tools.yaml\", \"--address\", \"0.0.0.0\"] depends_on: db: condition: service_healthy networks: - tool-network db: # TODO: It is recommended to pin to a specific image version instead of latest. image: postgres hostname: db environment: POSTGRES_USER: toolbox_user POSTGRES_PASSWORD: my-password POSTGRES_DB: toolbox_db ports: - \"5432:5432\" volumes: - ./db:/var/lib/postgresql/data # This file can be used to bootstrap your schema if needed. # See \"initialization scripts\" on https://hub.docker.com/_/postgres/ for more info - ./config/init.sql:/docker-entrypoint-initdb.d/init.sql healthcheck: test: [\"CMD-SHELL\", \"pg_isready -U toolbox_user -d toolbox_db\"] interval: 10s timeout: 5s retries: 5 networks: - tool-network networks: tool-network: Run the following command to bring up the Toolbox and Postgres instance\ndocker-compose up -d Tip\nYou can use this setup quickly set up Toolbox + Postgres to follow along in our Quickstart\nConnecting with Toolbox Client SDK Next, we will use Toolbox with the Client SDKs:\nThe url for the Toolbox server running using docker-compose will be:\nhttp://localhost:5000 Import and initialize the client with the URL:\nLangChain Llamaindex from toolbox_langchain import ToolboxClient # Replace with the cloud run service URL generated above async with ToolboxClient(\"http://$YOUR_URL\") as toolbox: from toolbox_llamaindex import ToolboxClient # Replace with the cloud run service URL generated above async with ToolboxClient(\"http://$YOUR_URL\") as toolbox: ","categories":"","description":"How to deploy Toolbox using Docker Compose.\n","excerpt":"How to deploy Toolbox using Docker Compose.\n","ref":"/genai-toolbox/how-to/deploy_docker/","tags":"","title":"Deploy using Docker Compose"},{"body":"","categories":"","description":"List of reference documentation for resources in Toolbox.\n","excerpt":"List of reference documentation for resources in Toolbox.\n","ref":"/genai-toolbox/resources/","tags":"","title":"Resources"},{"body":"About The OpenTelemetry Collector offers a vendor-agnostic implementation of how to receive, process and export telemetry data. It removes the need to run, operate, and maintain multiple agents/collectors.\nConfigure the Collector To configure the collector, you will have to provide a configuration file. The configuration file consists of four classes of pipeline component that access telemetry data.\nReceivers Processors Exporters Connectors Example of setting up the classes of pipeline components (in this example, we don’t use connectors):\nreceivers: otlp: protocols: http: endpoint: \"127.0.0.1:4553\" exporters: googlecloud: project: \u003cYOUR_GOOGLE_CLOUD_PROJECT\u003e processors: batch: send_batch_size: 200 After each pipeline component is configured, you will enable it within the service section of the configuration file.\nservice: pipelines: traces: receivers: [\"otlp\"] processors: [\"batch\"] exporters: [\"googlecloud\"] Running the Collector There are a couple of steps to run and use a Collector.\nInstall the Collector binary. Pull a binary or Docker image for the OpenTelemetry contrib collector.\nSet up credentials for telemetry backend.\nSet up the Collector config. Below are some examples for setting up the Collector config:\nGoogle Cloud Exporter Google Managed Service for Prometheus Exporter Run the Collector with the configuration file.\n./otelcol-contrib --config=collector-config.yaml Run toolbox with the --telemetry-otlp flag. Configure it to send them to http://127.0.0.1:4553 (for HTTP) or the Collector’s URL.\n./toolbox --telemetry-otlp=http://127.0.0.1:4553 Once telemetry datas are collected, you can view them in your telemetry backend. If you are using GCP exporters, telemetry will be visible in GCP dashboard at Metrics Explorer and Trace Explorer.\nNote\nIf you are exporting to Google Cloud monitoring, we recommend that you use the Google Cloud Exporter for traces and the Google Managed Service for Prometheus Exporter for metrics.\n","categories":"","description":"How to set up and configure Toolbox to use the Otel Collector.\n","excerpt":"How to set up and configure Toolbox to use the Otel Collector.\n","ref":"/genai-toolbox/how-to/export_telemetry/","tags":"","title":"Export Telemetry"},{"body":"","categories":"","description":"Samples and guides for using Toolbox.\n","excerpt":"Samples and guides for using Toolbox.\n","ref":"/genai-toolbox/samples/","tags":"","title":"Samples"},{"body":"","categories":"","description":"A list of other information related to Toolbox.\n","excerpt":"A list of other information related to Toolbox.\n","ref":"/genai-toolbox/about/","tags":"","title":"About"},{"body":"","categories":"","description":"Client SDKs to connect to the MCP Toolbox server.\n","excerpt":"Client SDKs to connect to the MCP Toolbox server.\n","ref":"/genai-toolbox/sdks/","tags":"","title":"SDKs"},{"body":"","categories":"","description":"","excerpt":"","ref":"/genai-toolbox/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/genai-toolbox/tags/","tags":"","title":"Tags"}]